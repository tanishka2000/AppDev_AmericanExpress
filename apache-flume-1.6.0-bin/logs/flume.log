04 Dec 2020 22:10:34,436 ERROR [main] (org.apache.flume.node.Application.main:353)  - A fatal error occurred while running. Exception follows.
org.apache.commons.cli.MissingArgumentException: Missing argument for option: n
	at org.apache.commons.cli.Parser.processArgs(Parser.java:343)
	at org.apache.commons.cli.Parser.processOption(Parser.java:393)
	at org.apache.commons.cli.Parser.parse(Parser.java:199)
	at org.apache.commons.cli.Parser.parse(Parser.java:85)
	at org.apache.flume.node.Application.main(Application.java:265)
04 Dec 2020 22:10:42,341 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
04 Dec 2020 22:10:42,347 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:conf/twitter.conf
04 Dec 2020 22:10:42,356 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:10:42,356 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:10:42,356 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:10:42,356 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:10:42,357 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:10:42,357 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
04 Dec 2020 22:10:42,357 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:10:42,357 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:10:42,358 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:10:42,372 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
04 Dec 2020 22:10:42,373 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
04 Dec 2020 22:10:42,379 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel MemChannel type memory
04 Dec 2020 22:10:42,383 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel MemChannel
04 Dec 2020 22:10:42,383 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
04 Dec 2020 22:10:42,390 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        ''qM5WhxIzaHRRvlqbcol7YhB1o''
04 Dec 2020 22:10:42,391 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     ''dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie''
04 Dec 2020 22:10:42,391 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        ''1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo''
04 Dec 2020 22:10:42,391 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: ''bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz''
04 Dec 2020 22:10:42,580 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
04 Dec 2020 22:10:42,594 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel MemChannel connected to [Twitter, HDFS]
04 Dec 2020 22:10:42,601 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@53067da9 counterGroup:{ name:null counters:{} } }} channels:{MemChannel=org.apache.flume.channel.MemoryChannel{name: MemChannel}} }
04 Dec 2020 22:10:42,610 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel MemChannel
04 Dec 2020 22:10:42,761 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: MemChannel: Successfully registered new MBean.
04 Dec 2020 22:10:42,762 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: MemChannel started
04 Dec 2020 22:10:42,762 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
04 Dec 2020 22:10:42,765 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
04 Dec 2020 22:10:42,766 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
04 Dec 2020 22:10:42,768 INFO  [lifecycleSupervisor-1-2] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
04 Dec 2020 22:10:42,768 INFO  [lifecycleSupervisor-1-2] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
04 Dec 2020 22:10:42,769 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
04 Dec 2020 22:10:42,769 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
04 Dec 2020 22:10:45,326 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

04 Dec 2020 22:10:45,328 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
04 Dec 2020 22:10:45,333 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 10000 milliseconds
04 Dec 2020 22:10:55,334 INFO  [Twitter Stream consumer-1[Waiting for 10000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
04 Dec 2020 22:10:56,430 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

04 Dec 2020 22:10:56,430 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
04 Dec 2020 22:10:56,432 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 20000 milliseconds
04 Dec 2020 22:11:16,433 INFO  [Twitter Stream consumer-1[Waiting for 20000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
04 Dec 2020 22:11:17,551 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

04 Dec 2020 22:11:17,553 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
04 Dec 2020 22:11:17,556 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 40000 milliseconds
04 Dec 2020 22:11:57,558 INFO  [Twitter Stream consumer-1[Waiting for 40000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
04 Dec 2020 22:11:59,794 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

04 Dec 2020 22:11:59,795 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
04 Dec 2020 22:11:59,798 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 80000 milliseconds
04 Dec 2020 22:12:46,956 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
04 Dec 2020 22:12:46,969 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: MemChannel stopped
04 Dec 2020 22:12:46,970 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.start.time == 1607100042762
04 Dec 2020 22:12:46,970 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.stop.time == 1607100166969
04 Dec 2020 22:12:46,970 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.capacity == 1000000
04 Dec 2020 22:12:46,971 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.current.size == 0
04 Dec 2020 22:12:46,973 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.attempt == 0
04 Dec 2020 22:12:46,973 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.success == 0
04 Dec 2020 22:12:46,974 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.attempt == 17
04 Dec 2020 22:12:46,974 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.success == 0
04 Dec 2020 22:12:46,974 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
04 Dec 2020 22:12:46,975 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
04 Dec 2020 22:12:46,976 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
04 Dec 2020 22:12:46,977 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
04 Dec 2020 22:12:46,978 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607100042768
04 Dec 2020 22:12:46,978 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607100166977
04 Dec 2020 22:12:46,978 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
04 Dec 2020 22:12:46,978 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 17
04 Dec 2020 22:12:46,979 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
04 Dec 2020 22:12:46,979 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
04 Dec 2020 22:12:46,979 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
04 Dec 2020 22:12:46,979 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
04 Dec 2020 22:12:46,980 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
04 Dec 2020 22:12:46,980 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
04 Dec 2020 22:12:59,851 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
04 Dec 2020 22:12:59,882 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:conf/twitter.conf
04 Dec 2020 22:12:59,912 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:12:59,913 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:12:59,914 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:12:59,914 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:12:59,915 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:12:59,915 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
04 Dec 2020 22:12:59,916 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:12:59,916 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:12:59,917 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
04 Dec 2020 22:12:59,964 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
04 Dec 2020 22:12:59,965 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
04 Dec 2020 22:12:59,983 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel MemChannel type memory
04 Dec 2020 22:12:59,997 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel MemChannel
04 Dec 2020 22:13:00,002 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
04 Dec 2020 22:13:00,026 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        ''qM5WhxIzaHRRvlqbcol7YhB1o''
04 Dec 2020 22:13:00,027 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     ''dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie''
04 Dec 2020 22:13:00,028 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        ''1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo''
04 Dec 2020 22:13:00,028 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: ''bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz''
04 Dec 2020 22:13:00,656 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
04 Dec 2020 22:13:00,695 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel MemChannel connected to [Twitter, HDFS]
04 Dec 2020 22:13:00,712 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@7154faf2 counterGroup:{ name:null counters:{} } }} channels:{MemChannel=org.apache.flume.channel.MemoryChannel{name: MemChannel}} }
04 Dec 2020 22:13:00,737 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel MemChannel
04 Dec 2020 22:13:01,132 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: MemChannel: Successfully registered new MBean.
04 Dec 2020 22:13:01,132 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: MemChannel started
04 Dec 2020 22:13:01,136 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
04 Dec 2020 22:13:01,139 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
04 Dec 2020 22:13:01,139 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
04 Dec 2020 22:13:01,141 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
04 Dec 2020 22:13:01,142 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
04 Dec 2020 22:13:01,161 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
04 Dec 2020 22:13:01,161 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
04 Dec 2020 22:13:04,119 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

04 Dec 2020 22:13:04,124 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
04 Dec 2020 22:13:04,129 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 10000 milliseconds
04 Dec 2020 22:13:14,130 INFO  [Twitter Stream consumer-1[Waiting for 10000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
04 Dec 2020 22:13:15,780 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

04 Dec 2020 22:13:15,781 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
04 Dec 2020 22:13:15,782 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 20000 milliseconds
04 Dec 2020 22:13:35,784 INFO  [Twitter Stream consumer-1[Waiting for 20000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
04 Dec 2020 22:13:37,393 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

04 Dec 2020 22:13:37,394 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
04 Dec 2020 22:13:37,394 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 40000 milliseconds
04 Dec 2020 22:14:17,395 INFO  [Twitter Stream consumer-1[Waiting for 40000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
04 Dec 2020 22:14:19,626 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

04 Dec 2020 22:14:19,627 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
04 Dec 2020 22:14:19,628 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 80000 milliseconds
04 Dec 2020 22:15:39,629 INFO  [Twitter Stream consumer-1[Waiting for 80000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
04 Dec 2020 22:15:48,493 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

04 Dec 2020 22:15:48,493 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
04 Dec 2020 22:15:48,494 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 160000 milliseconds
04 Dec 2020 22:18:28,494 INFO  [Twitter Stream consumer-1[Waiting for 160000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
04 Dec 2020 22:18:30,499 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

04 Dec 2020 22:18:30,499 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
04 Dec 2020 22:18:30,500 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 240000 milliseconds
04 Dec 2020 22:19:11,943 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
04 Dec 2020 22:19:11,959 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
04 Dec 2020 22:19:11,960 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
04 Dec 2020 22:19:11,960 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607100181139
04 Dec 2020 22:19:11,961 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607100551960
04 Dec 2020 22:19:11,961 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
04 Dec 2020 22:19:11,961 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 48
04 Dec 2020 22:19:11,961 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
04 Dec 2020 22:19:11,961 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
04 Dec 2020 22:19:11,961 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
04 Dec 2020 22:19:11,961 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
04 Dec 2020 22:19:11,962 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
04 Dec 2020 22:19:11,962 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
04 Dec 2020 22:19:11,962 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
04 Dec 2020 22:19:11,962 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
04 Dec 2020 22:19:11,962 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: MemChannel stopped
04 Dec 2020 22:19:11,962 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.start.time == 1607100181132
04 Dec 2020 22:19:11,962 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.stop.time == 1607100551962
04 Dec 2020 22:19:11,962 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.capacity == 1000000
04 Dec 2020 22:19:11,963 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.current.size == 0
04 Dec 2020 22:19:11,963 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.attempt == 0
04 Dec 2020 22:19:11,963 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.success == 0
04 Dec 2020 22:19:11,963 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.attempt == 48
04 Dec 2020 22:19:11,963 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.success == 0
04 Dec 2020 23:57:10,527 ERROR [main] (org.apache.flume.node.Application.main:353)  - A fatal error occurred while running. Exception follows.
org.apache.commons.cli.ParseException: The specified configuration file does not exist: /home/tanishka/Downloads/Flume/flume.conf
	at org.apache.flume.node.Application.main(Application.java:319)
05 Dec 2020 00:58:55,054 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
05 Dec 2020 00:58:55,072 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:conf/twitter.conf
05 Dec 2020 00:58:55,087 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 00:58:55,087 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 00:58:55,088 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 00:58:55,088 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 00:58:55,088 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 00:58:55,088 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 00:58:55,089 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 00:58:55,089 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 00:58:55,089 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 00:58:55,112 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 00:58:55,113 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 00:58:55,120 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel MemChannel type memory
05 Dec 2020 00:58:55,128 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel MemChannel
05 Dec 2020 00:58:55,129 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 00:58:55,198 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        ''qM5WhxIzaHRRvlqbcol7YhB1o''
05 Dec 2020 00:58:55,198 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     ''dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie''
05 Dec 2020 00:58:55,198 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        ''1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo''
05 Dec 2020 00:58:55,198 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: ''bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz''
05 Dec 2020 00:58:55,528 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 00:58:55,547 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel MemChannel connected to [Twitter, HDFS]
05 Dec 2020 00:58:55,557 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@7154faf2 counterGroup:{ name:null counters:{} } }} channels:{MemChannel=org.apache.flume.channel.MemoryChannel{name: MemChannel}} }
05 Dec 2020 00:58:55,575 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel MemChannel
05 Dec 2020 00:58:55,797 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: MemChannel: Successfully registered new MBean.
05 Dec 2020 00:58:55,797 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: MemChannel started
05 Dec 2020 00:58:55,797 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 00:58:55,798 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 00:58:55,812 INFO  [lifecycleSupervisor-1-2] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 00:58:55,813 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 00:58:55,813 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 00:58:55,815 INFO  [lifecycleSupervisor-1-2] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 00:58:55,815 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 00:58:58,188 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 00:58:58,189 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 00:58:58,194 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 10000 milliseconds
05 Dec 2020 00:59:08,194 INFO  [Twitter Stream consumer-1[Waiting for 10000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 00:59:09,154 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 00:59:09,155 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 00:59:09,155 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 20000 milliseconds
05 Dec 2020 00:59:29,155 INFO  [Twitter Stream consumer-1[Waiting for 20000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 00:59:30,282 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 00:59:30,282 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 00:59:30,283 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 40000 milliseconds
05 Dec 2020 01:00:10,283 INFO  [Twitter Stream consumer-1[Waiting for 40000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:00:11,563 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:00:11,564 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:00:11,566 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 80000 milliseconds
05 Dec 2020 01:01:31,567 INFO  [Twitter Stream consumer-1[Waiting for 80000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:01:32,496 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:01:32,496 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:01:32,497 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 160000 milliseconds
05 Dec 2020 01:04:12,498 INFO  [Twitter Stream consumer-1[Waiting for 160000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:04:14,734 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:04:14,734 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:04:14,735 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 240000 milliseconds
05 Dec 2020 01:08:14,736 INFO  [Twitter Stream consumer-1[Waiting for 240000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:08:16,001 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:08:16,002 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:08:16,003 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 240000 milliseconds
05 Dec 2020 01:12:16,004 INFO  [Twitter Stream consumer-1[Waiting for 240000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:12:18,604 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:12:18,605 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:12:18,606 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 240000 milliseconds
05 Dec 2020 01:12:35,165 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
05 Dec 2020 01:12:35,176 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
05 Dec 2020 01:12:35,177 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 01:12:35,177 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607110135813
05 Dec 2020 01:12:35,177 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607110955177
05 Dec 2020 01:12:35,177 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 01:12:35,177 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 104
05 Dec 2020 01:12:35,177 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
05 Dec 2020 01:12:35,178 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 01:12:35,178 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
05 Dec 2020 01:12:35,178 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
05 Dec 2020 01:12:35,178 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
05 Dec 2020 01:12:35,178 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 01:12:35,178 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 01:12:35,178 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 01:12:35,178 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: MemChannel stopped
05 Dec 2020 01:12:35,178 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.start.time == 1607110135797
05 Dec 2020 01:12:35,179 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.stop.time == 1607110955178
05 Dec 2020 01:12:35,179 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.capacity == 10000
05 Dec 2020 01:12:35,179 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.current.size == 0
05 Dec 2020 01:12:35,179 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.attempt == 0
05 Dec 2020 01:12:35,179 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.success == 0
05 Dec 2020 01:12:35,179 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.attempt == 104
05 Dec 2020 01:12:35,179 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.success == 0
05 Dec 2020 01:13:00,053 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
05 Dec 2020 01:13:00,061 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:conf/twitter.conf
05 Dec 2020 01:13:00,070 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:13:00,071 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:13:00,071 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:13:00,071 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:13:00,071 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:13:00,071 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 01:13:00,072 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:13:00,072 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:13:00,072 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:13:00,089 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 01:13:00,089 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 01:13:00,096 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel MemChannel type memory
05 Dec 2020 01:13:00,101 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel MemChannel
05 Dec 2020 01:13:00,102 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 01:13:00,109 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        ''qM5WhxIzaHRRvlqbcol7YhB1o''
05 Dec 2020 01:13:00,109 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     ''dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie''
05 Dec 2020 01:13:00,109 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        ''1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo''
05 Dec 2020 01:13:00,109 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: ''bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz''
05 Dec 2020 01:13:00,302 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 01:13:00,319 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel MemChannel connected to [Twitter, HDFS]
05 Dec 2020 01:13:00,326 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@53067da9 counterGroup:{ name:null counters:{} } }} channels:{MemChannel=org.apache.flume.channel.MemoryChannel{name: MemChannel}} }
05 Dec 2020 01:13:00,336 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel MemChannel
05 Dec 2020 01:13:00,487 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: MemChannel: Successfully registered new MBean.
05 Dec 2020 01:13:00,487 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: MemChannel started
05 Dec 2020 01:13:00,487 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 01:13:00,488 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 01:13:00,489 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 01:13:00,492 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 01:13:00,492 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:13:00,493 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 01:13:00,493 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 01:13:02,770 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:13:02,771 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:13:02,775 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 10000 milliseconds
05 Dec 2020 01:13:12,777 INFO  [Twitter Stream consumer-1[Waiting for 10000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:13:14,517 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:13:14,517 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:13:14,517 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 20000 milliseconds
05 Dec 2020 01:13:34,523 INFO  [Twitter Stream consumer-1[Waiting for 20000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:13:36,693 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:13:36,694 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:13:36,695 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 40000 milliseconds
05 Dec 2020 01:14:16,697 INFO  [Twitter Stream consumer-1[Waiting for 40000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:14:19,587 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:14:19,588 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:14:19,591 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 80000 milliseconds
05 Dec 2020 01:15:01,986 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
05 Dec 2020 01:15:02,006 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: MemChannel stopped
05 Dec 2020 01:15:02,007 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.start.time == 1607110980487
05 Dec 2020 01:15:02,008 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.stop.time == 1607111102006
05 Dec 2020 01:15:02,009 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.capacity == 10
05 Dec 2020 01:15:02,009 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.current.size == 0
05 Dec 2020 01:15:02,010 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.attempt == 0
05 Dec 2020 01:15:02,010 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.success == 0
05 Dec 2020 01:15:02,011 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.attempt == 17
05 Dec 2020 01:15:02,012 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.success == 0
05 Dec 2020 01:15:02,013 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
05 Dec 2020 01:15:02,016 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 01:15:02,017 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 01:15:02,019 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 01:15:02,019 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607110980493
05 Dec 2020 01:15:02,019 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607111102018
05 Dec 2020 01:15:02,020 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 01:15:02,020 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 17
05 Dec 2020 01:15:02,023 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
05 Dec 2020 01:15:02,023 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 01:15:02,024 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
05 Dec 2020 01:15:02,024 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
05 Dec 2020 01:15:02,025 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
05 Dec 2020 01:15:02,025 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 01:15:49,896 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
05 Dec 2020 01:15:49,903 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:conf/twitter.conf
05 Dec 2020 01:15:49,913 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:15:49,913 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:15:49,913 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:15:49,913 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:15:49,914 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:15:49,914 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 01:15:49,914 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:15:49,914 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:15:49,915 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:15:49,931 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 01:15:49,932 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 01:15:49,938 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel MemChannel type memory
05 Dec 2020 01:15:49,943 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel MemChannel
05 Dec 2020 01:15:49,944 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 01:15:49,951 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        ''qM5WhxIzaHRRvlqbcol7YhB1o''
05 Dec 2020 01:15:49,952 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     ''dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie''
05 Dec 2020 01:15:49,952 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        ''1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo''
05 Dec 2020 01:15:49,952 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: ''bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz''
05 Dec 2020 01:15:50,142 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 01:15:50,156 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel MemChannel connected to [Twitter, HDFS]
05 Dec 2020 01:15:50,164 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@53067da9 counterGroup:{ name:null counters:{} } }} channels:{MemChannel=org.apache.flume.channel.MemoryChannel{name: MemChannel}} }
05 Dec 2020 01:15:50,174 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel MemChannel
05 Dec 2020 01:15:50,321 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: MemChannel: Successfully registered new MBean.
05 Dec 2020 01:15:50,321 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: MemChannel started
05 Dec 2020 01:15:50,321 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 01:15:50,322 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 01:15:50,325 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 01:15:50,325 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 01:15:50,326 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 01:15:50,326 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 01:15:50,326 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:15:53,349 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:15:53,350 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:15:53,374 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 10000 milliseconds
05 Dec 2020 01:16:03,376 INFO  [Twitter Stream consumer-1[Waiting for 10000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:16:05,030 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:16:05,031 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:16:05,032 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 20000 milliseconds
05 Dec 2020 01:16:25,038 INFO  [Twitter Stream consumer-1[Waiting for 20000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:16:29,827 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:16:29,829 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:16:29,832 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 40000 milliseconds
05 Dec 2020 01:17:09,833 INFO  [Twitter Stream consumer-1[Waiting for 40000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:17:11,749 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:17:11,750 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:17:11,751 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 80000 milliseconds
05 Dec 2020 01:17:24,863 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
05 Dec 2020 01:17:24,879 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: MemChannel stopped
05 Dec 2020 01:17:24,880 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.start.time == 1607111150321
05 Dec 2020 01:17:24,880 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.stop.time == 1607111244879
05 Dec 2020 01:17:24,881 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.capacity == 10
05 Dec 2020 01:17:24,882 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.current.size == 0
05 Dec 2020 01:17:24,883 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.attempt == 0
05 Dec 2020 01:17:24,883 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.success == 0
05 Dec 2020 01:17:24,884 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.attempt == 14
05 Dec 2020 01:17:24,884 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.success == 0
05 Dec 2020 01:17:24,884 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
05 Dec 2020 01:17:24,885 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 01:17:24,886 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 01:17:24,891 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 01:17:24,892 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607111150326
05 Dec 2020 01:17:24,892 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607111244891
05 Dec 2020 01:17:24,893 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 01:17:24,893 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 14
05 Dec 2020 01:17:24,893 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
05 Dec 2020 01:17:24,894 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 01:17:24,894 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
05 Dec 2020 01:17:24,894 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
05 Dec 2020 01:17:24,894 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
05 Dec 2020 01:17:24,895 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 01:17:34,527 ERROR [main] (org.apache.flume.node.Application.main:353)  - A fatal error occurred while running. Exception follows.
org.apache.commons.cli.ParseException: The specified configuration file does not exist: /home/tanishka/Downloads/Flume/apache-flume-1.6.0-bin/conf/twitter-conf
	at org.apache.flume.node.Application.main(Application.java:319)
05 Dec 2020 01:18:26,959 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
05 Dec 2020 01:18:26,968 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:conf/twitter.conf
05 Dec 2020 01:18:26,981 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:18:26,981 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:18:26,981 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:18:26,981 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:18:26,982 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:18:26,982 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 01:18:26,982 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:18:26,983 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:18:26,983 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:18:27,001 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 01:18:27,001 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 01:18:27,020 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel MemChannel type memory
05 Dec 2020 01:18:27,024 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel MemChannel
05 Dec 2020 01:18:27,024 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 01:18:27,031 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        ''qM5WhxIzaHRRvlqbcol7YhB1o''
05 Dec 2020 01:18:27,031 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     ''dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie''
05 Dec 2020 01:18:27,032 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        ''1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo''
05 Dec 2020 01:18:27,032 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: ''bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz''
05 Dec 2020 01:18:27,232 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 01:18:27,243 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel MemChannel connected to [Twitter, HDFS]
05 Dec 2020 01:18:27,250 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@1df3a121 counterGroup:{ name:null counters:{} } }} channels:{MemChannel=org.apache.flume.channel.MemoryChannel{name: MemChannel}} }
05 Dec 2020 01:18:27,263 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel MemChannel
05 Dec 2020 01:18:27,425 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: MemChannel: Successfully registered new MBean.
05 Dec 2020 01:18:27,426 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: MemChannel started
05 Dec 2020 01:18:27,426 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 01:18:27,427 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 01:18:27,428 INFO  [lifecycleSupervisor-1-2] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 01:18:27,437 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 01:18:27,438 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 01:18:27,438 INFO  [lifecycleSupervisor-1-2] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 01:18:27,438 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:18:29,195 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:18:29,196 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:18:29,201 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 10000 milliseconds
05 Dec 2020 01:18:39,202 INFO  [Twitter Stream consumer-1[Waiting for 10000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:18:40,081 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:18:40,081 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:18:40,082 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 20000 milliseconds
05 Dec 2020 01:19:00,082 INFO  [Twitter Stream consumer-1[Waiting for 20000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:19:01,192 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:19:01,192 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:19:01,194 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 40000 milliseconds
05 Dec 2020 01:19:41,195 INFO  [Twitter Stream consumer-1[Waiting for 40000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:19:42,195 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:19:42,196 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:19:42,198 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 80000 milliseconds
05 Dec 2020 01:21:02,199 INFO  [Twitter Stream consumer-1[Waiting for 80000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:21:03,102 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:21:03,102 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:21:03,103 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 160000 milliseconds
05 Dec 2020 01:23:43,110 INFO  [Twitter Stream consumer-1[Waiting for 160000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:23:44,111 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:23:44,112 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:23:44,114 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 240000 milliseconds
05 Dec 2020 01:27:44,117 INFO  [Twitter Stream consumer-1[Waiting for 240000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:27:47,952 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:27:47,952 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:27:47,953 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 240000 milliseconds
05 Dec 2020 01:29:57,440 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:conf/twitter.conf
05 Dec 2020 01:29:57,442 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:29:57,443 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:29:57,443 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:29:57,443 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:29:57,444 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:29:57,444 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 01:29:57,444 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:29:57,444 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:29:57,444 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:29:57,458 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 01:29:57,458 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 01:29:57,458 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel MemChannel
05 Dec 2020 01:29:57,459 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 01:29:57,459 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        ''qM5WhxIzaHRRvlqbcol7YhB1o''
05 Dec 2020 01:29:57,459 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     ''dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie''
05 Dec 2020 01:29:57,459 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        ''1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo''
05 Dec 2020 01:29:57,459 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: ''bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz''
05 Dec 2020 01:29:57,460 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 01:29:57,460 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel MemChannel connected to [Twitter, HDFS]
05 Dec 2020 01:29:57,461 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.stopAllComponents:101)  - Shutting down configuration: { sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:START} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@1df3a121 counterGroup:{ name:null counters:{runner.backoffs.consecutive=88, runner.backoffs=88} } }} channels:{MemChannel=org.apache.flume.channel.MemoryChannel{name: MemChannel}} }
05 Dec 2020 01:29:57,461 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.stopAllComponents:105)  - Stopping Source Twitter
05 Dec 2020 01:29:57,461 INFO  [conf-file-poller-0] (org.apache.flume.lifecycle.LifecycleSupervisor.unsupervise:171)  - Stopping component: EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:START} }
05 Dec 2020 01:29:57,461 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 01:29:57,461 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 01:29:57,461 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.stopAllComponents:115)  - Stopping Sink HDFS
05 Dec 2020 01:29:57,462 INFO  [conf-file-poller-0] (org.apache.flume.lifecycle.LifecycleSupervisor.unsupervise:171)  - Stopping component: SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@1df3a121 counterGroup:{ name:null counters:{runner.backoffs.consecutive=88, runner.backoffs=88} } }
05 Dec 2020 01:29:57,462 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 01:29:57,463 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607111307438
05 Dec 2020 01:29:57,463 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607111997462
05 Dec 2020 01:29:57,463 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 01:29:57,463 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 88
05 Dec 2020 01:29:57,463 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
05 Dec 2020 01:29:57,463 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 01:29:57,463 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
05 Dec 2020 01:29:57,464 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
05 Dec 2020 01:29:57,464 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
05 Dec 2020 01:29:57,464 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 01:29:57,464 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.stopAllComponents:125)  - Stopping Channel MemChannel
05 Dec 2020 01:29:57,464 INFO  [conf-file-poller-0] (org.apache.flume.lifecycle.LifecycleSupervisor.unsupervise:171)  - Stopping component: org.apache.flume.channel.MemoryChannel{name: MemChannel}
05 Dec 2020 01:29:57,470 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: MemChannel stopped
05 Dec 2020 01:29:57,470 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.start.time == 1607111307426
05 Dec 2020 01:29:57,470 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.stop.time == 1607111997470
05 Dec 2020 01:29:57,470 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.capacity == 10
05 Dec 2020 01:29:57,470 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.current.size == 0
05 Dec 2020 01:29:57,471 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.attempt == 0
05 Dec 2020 01:29:57,471 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.success == 0
05 Dec 2020 01:29:57,471 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.attempt == 88
05 Dec 2020 01:29:57,471 INFO  [conf-file-poller-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.success == 0
05 Dec 2020 01:29:57,471 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@14e8b04a counterGroup:{ name:null counters:{} } }} channels:{MemChannel=org.apache.flume.channel.MemoryChannel{name: MemChannel}} }
05 Dec 2020 01:29:57,471 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel MemChannel
05 Dec 2020 01:29:57,472 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:160)  - Waiting for channel: MemChannel to start. Sleeping for 500 ms
05 Dec 2020 01:29:57,472 INFO  [lifecycleSupervisor-1-7] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: MemChannel started
05 Dec 2020 01:29:57,972 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 01:29:57,973 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 01:29:57,974 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 01:29:57,974 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 01:29:57,974 INFO  [lifecycleSupervisor-1-6] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 01:29:57,976 INFO  [lifecycleSupervisor-1-6] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 01:29:57,976 INFO  [Twitter Stream consumer-2[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:30:00,465 INFO  [Twitter Stream consumer-2[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:30:00,467 ERROR [Twitter Stream consumer-2[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:30:00,469 INFO  [Twitter Stream consumer-2[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 10000 milliseconds
05 Dec 2020 01:30:10,472 INFO  [Twitter Stream consumer-2[Waiting for 10000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:30:11,521 INFO  [Twitter Stream consumer-2[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:30:11,522 ERROR [Twitter Stream consumer-2[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:30:11,525 INFO  [Twitter Stream consumer-2[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 20000 milliseconds
05 Dec 2020 01:30:31,528 INFO  [Twitter Stream consumer-2[Waiting for 20000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:30:32,406 INFO  [Twitter Stream consumer-2[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:30:32,406 ERROR [Twitter Stream consumer-2[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:30:32,407 INFO  [Twitter Stream consumer-2[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 40000 milliseconds
05 Dec 2020 01:30:50,060 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
05 Dec 2020 01:30:50,070 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
05 Dec 2020 01:30:50,073 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: MemChannel stopped
05 Dec 2020 01:30:50,074 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.start.time == 1607111997472
05 Dec 2020 01:30:50,074 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.stop.time == 1607112050073
05 Dec 2020 01:30:50,075 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.capacity == 10
05 Dec 2020 01:30:50,075 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.current.size == 0
05 Dec 2020 01:30:50,076 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.attempt == 0
05 Dec 2020 01:30:50,076 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.success == 0
05 Dec 2020 01:30:50,077 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.attempt == 8
05 Dec 2020 01:30:50,077 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.success == 0
05 Dec 2020 01:30:50,080 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 01:30:50,081 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607111997974
05 Dec 2020 01:30:50,082 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607112050080
05 Dec 2020 01:30:50,083 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 01:30:50,084 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 8
05 Dec 2020 01:30:50,085 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
05 Dec 2020 01:30:50,085 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 01:30:50,086 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
05 Dec 2020 01:30:50,087 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
05 Dec 2020 01:30:50,088 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
05 Dec 2020 01:30:50,089 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 01:30:50,089 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 01:30:50,090 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 01:31:48,186 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
05 Dec 2020 01:31:48,193 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:/home/tanishka/Downloads/Flume/apache-flume-1.6.0-bin/conf/twitter.conf
05 Dec 2020 01:31:48,203 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:31:48,203 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:31:48,203 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:31:48,203 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:31:48,204 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:31:48,204 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 01:31:48,204 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:31:48,204 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:31:48,205 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:31:48,224 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 01:31:48,225 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 01:31:48,231 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel MemChannel type memory
05 Dec 2020 01:31:48,235 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel MemChannel
05 Dec 2020 01:31:48,236 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 01:31:48,243 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        ''qM5WhxIzaHRRvlqbcol7YhB1o''
05 Dec 2020 01:31:48,243 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     ''dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie''
05 Dec 2020 01:31:48,243 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        ''1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo''
05 Dec 2020 01:31:48,244 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: ''bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz''
05 Dec 2020 01:31:48,433 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 01:31:48,445 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel MemChannel connected to [Twitter, HDFS]
05 Dec 2020 01:31:48,453 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@53067da9 counterGroup:{ name:null counters:{} } }} channels:{MemChannel=org.apache.flume.channel.MemoryChannel{name: MemChannel}} }
05 Dec 2020 01:31:48,463 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel MemChannel
05 Dec 2020 01:31:48,611 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: MemChannel: Successfully registered new MBean.
05 Dec 2020 01:31:48,611 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: MemChannel started
05 Dec 2020 01:31:48,612 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 01:31:48,612 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 01:31:48,613 INFO  [lifecycleSupervisor-1-2] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 01:31:48,623 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 01:31:48,623 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 01:31:48,627 INFO  [lifecycleSupervisor-1-2] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 01:31:48,627 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:31:50,244 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:31:50,245 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:31:50,251 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 10000 milliseconds
05 Dec 2020 01:32:00,253 INFO  [Twitter Stream consumer-1[Waiting for 10000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:32:01,438 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:32:01,438 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:32:01,438 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 20000 milliseconds
05 Dec 2020 01:32:21,439 INFO  [Twitter Stream consumer-1[Waiting for 20000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:32:22,583 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:32:22,584 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:32:22,586 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 40000 milliseconds
05 Dec 2020 01:33:02,609 INFO  [Twitter Stream consumer-1[Waiting for 40000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:33:03,834 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:33:03,835 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:33:03,837 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 80000 milliseconds
05 Dec 2020 01:34:23,840 INFO  [Twitter Stream consumer-1[Waiting for 80000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:34:24,931 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:34:24,932 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:34:24,934 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 160000 milliseconds
05 Dec 2020 01:36:40,147 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
05 Dec 2020 01:36:40,154 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: MemChannel stopped
05 Dec 2020 01:36:40,154 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.start.time == 1607112108611
05 Dec 2020 01:36:40,154 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.stop.time == 1607112400154
05 Dec 2020 01:36:40,156 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.capacity == 10
05 Dec 2020 01:36:40,156 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.current.size == 0
05 Dec 2020 01:36:40,156 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.attempt == 0
05 Dec 2020 01:36:40,157 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.success == 0
05 Dec 2020 01:36:40,157 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.attempt == 38
05 Dec 2020 01:36:40,157 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.success == 0
05 Dec 2020 01:36:40,162 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
05 Dec 2020 01:36:40,163 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 01:36:40,164 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 01:36:40,165 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 01:36:40,165 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607112108623
05 Dec 2020 01:36:40,166 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607112400165
05 Dec 2020 01:36:40,166 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 01:36:40,166 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 38
05 Dec 2020 01:36:40,166 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
05 Dec 2020 01:36:40,167 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 01:36:40,167 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
05 Dec 2020 01:36:40,167 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
05 Dec 2020 01:36:40,167 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
05 Dec 2020 01:36:40,168 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 01:37:58,867 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
05 Dec 2020 01:37:58,873 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:/home/tanishka/Downloads/Flume/apache-flume-1.6.0-bin/conf/twitter.conf
05 Dec 2020 01:37:58,882 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:37:58,882 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:37:58,882 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:37:58,882 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:37:58,883 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:37:58,883 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 01:37:58,883 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:37:58,883 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:37:58,884 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 01:37:58,903 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 01:37:58,903 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 01:37:58,909 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel MemChannel type memory
05 Dec 2020 01:37:58,913 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel MemChannel
05 Dec 2020 01:37:58,914 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 01:37:58,921 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        ''qM5WhxIzaHRRvlqbcol7YhB1o''
05 Dec 2020 01:37:58,921 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     ''dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie''
05 Dec 2020 01:37:58,922 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        ''1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo''
05 Dec 2020 01:37:58,922 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: ''bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz''
05 Dec 2020 01:37:59,120 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 01:37:59,135 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel MemChannel connected to [Twitter, HDFS]
05 Dec 2020 01:37:59,142 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@7154faf2 counterGroup:{ name:null counters:{} } }} channels:{MemChannel=org.apache.flume.channel.MemoryChannel{name: MemChannel}} }
05 Dec 2020 01:37:59,152 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel MemChannel
05 Dec 2020 01:37:59,340 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: MemChannel: Successfully registered new MBean.
05 Dec 2020 01:37:59,341 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: MemChannel started
05 Dec 2020 01:37:59,341 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 01:37:59,342 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 01:37:59,343 INFO  [lifecycleSupervisor-1-4] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 01:37:59,355 INFO  [lifecycleSupervisor-1-3] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 01:37:59,355 INFO  [lifecycleSupervisor-1-4] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 01:37:59,355 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:37:59,355 INFO  [lifecycleSupervisor-1-3] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 01:38:00,903 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:38:00,904 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:38:00,910 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 10000 milliseconds
05 Dec 2020 01:38:10,913 INFO  [Twitter Stream consumer-1[Waiting for 10000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:38:12,891 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:38:12,891 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:38:12,893 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 20000 milliseconds
05 Dec 2020 01:38:32,894 INFO  [Twitter Stream consumer-1[Waiting for 20000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:38:34,126 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:38:34,127 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:38:34,130 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 40000 milliseconds
05 Dec 2020 01:39:14,135 INFO  [Twitter Stream consumer-1[Waiting for 40000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:39:15,116 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:39:15,117 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:39:15,119 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 80000 milliseconds
05 Dec 2020 01:40:35,121 INFO  [Twitter Stream consumer-1[Waiting for 80000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:40:36,991 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:40:36,994 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:40:36,996 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 160000 milliseconds
05 Dec 2020 01:43:16,998 INFO  [Twitter Stream consumer-1[Waiting for 160000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:43:20,231 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:43:20,232 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:43:20,233 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 240000 milliseconds
05 Dec 2020 01:47:20,234 INFO  [Twitter Stream consumer-1[Waiting for 240000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:47:21,162 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:47:21,163 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:47:21,174 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 240000 milliseconds
05 Dec 2020 01:51:21,176 INFO  [Twitter Stream consumer-1[Waiting for 240000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:51:24,344 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:51:24,344 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:51:24,346 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 240000 milliseconds
05 Dec 2020 01:55:24,349 INFO  [Twitter Stream consumer-1[Waiting for 240000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 01:55:28,500 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - 401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

05 Dec 2020 01:55:28,501 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
401:Authentication credentials (https://dev.twitter.com/pages/auth) were missing or incorrect. Ensure that you have set valid consumer key/secret, access token/secret, and the system clock is in sync.
<html>\n<head>\n<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>\n<title>Error 401 Unauthorized</title>
</head>
<body>
<h2>HTTP ERROR: 401</h2>
<p>Problem accessing '/1.1/statuses/sample.json?stall_warnings=true'. Reason:
<pre>    Unauthorized</pre>
</body>
</html>

Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75513
TwitterException{exceptionCode=[d0031b0b-1db75513], statusCode=401, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:177)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
05 Dec 2020 01:55:28,502 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 240000 milliseconds
05 Dec 2020 01:57:22,270 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
05 Dec 2020 01:57:22,292 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
05 Dec 2020 01:57:22,295 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 01:57:22,296 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607112479355
05 Dec 2020 01:57:22,297 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607113642295
05 Dec 2020 01:57:22,298 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 01:57:22,298 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 147
05 Dec 2020 01:57:22,299 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
05 Dec 2020 01:57:22,299 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 01:57:22,300 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
05 Dec 2020 01:57:22,301 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
05 Dec 2020 01:57:22,302 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
05 Dec 2020 01:57:22,302 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 01:57:22,303 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 01:57:22,304 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 01:57:22,305 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: MemChannel stopped
05 Dec 2020 01:57:22,305 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.start.time == 1607112479341
05 Dec 2020 01:57:22,306 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.stop.time == 1607113642305
05 Dec 2020 01:57:22,307 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.capacity == 10
05 Dec 2020 01:57:22,307 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.current.size == 0
05 Dec 2020 01:57:22,308 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.attempt == 0
05 Dec 2020 01:57:22,308 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.put.success == 0
05 Dec 2020 01:57:22,309 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.attempt == 147
05 Dec 2020 01:57:22,309 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: MemChannel. channel.event.take.success == 0
05 Dec 2020 15:12:09,867 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
05 Dec 2020 15:12:09,902 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:/home/tanishka/Downloads/Flume/apache-flume-1.6.0-bin/conf/twitter.conf
05 Dec 2020 15:12:09,923 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 15:12:09,924 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 15:12:09,924 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 15:12:09,924 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 15:12:09,924 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 15:12:09,925 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 15:12:09,925 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 15:12:09,925 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 15:12:09,926 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 15:12:09,969 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 15:12:09,969 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 15:12:09,979 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel FileChannel type memory
05 Dec 2020 15:12:09,985 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel FileChannel
05 Dec 2020 15:12:09,986 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 15:12:09,995 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        'qM5WhxIzaHRRvlqbcol7YhB1o'
05 Dec 2020 15:12:09,995 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     'dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie'
05 Dec 2020 15:12:09,995 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        '1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo'
05 Dec 2020 15:12:09,995 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: 'bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz'
05 Dec 2020 15:12:10,265 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 15:12:10,318 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel FileChannel connected to [Twitter, HDFS]
05 Dec 2020 15:12:10,327 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@53067da9 counterGroup:{ name:null counters:{} } }} channels:{FileChannel=org.apache.flume.channel.MemoryChannel{name: FileChannel}} }
05 Dec 2020 15:12:10,342 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel FileChannel
05 Dec 2020 15:12:10,557 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: FileChannel: Successfully registered new MBean.
05 Dec 2020 15:12:10,558 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: FileChannel started
05 Dec 2020 15:12:10,558 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 15:12:10,559 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 15:12:10,570 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 15:12:10,570 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 15:12:10,572 INFO  [lifecycleSupervisor-1-4] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 15:12:10,574 INFO  [lifecycleSupervisor-1-4] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 15:12:10,574 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 15:12:17,097 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Connection established.
05 Dec 2020 15:12:17,097 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Receiving status stream.
05 Dec 2020 15:12:17,194 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.HDFSDataStream.configure:58)  - Serializer = TEXT, UseRawLocalFileSystem = false
05 Dec 2020 15:12:17,312 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.HDFSEventSink.process:459)  - process failed
java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:1380)
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:1361)
	at org.apache.hadoop.conf.Configuration.setBoolean(Configuration.java:1703)
	at org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:209)
	at org.apache.flume.sink.hdfs.BucketWriter.append(BucketWriter.java:514)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:418)
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:748)
05 Dec 2020 15:12:20,034 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 100 docs
05 Dec 2020 15:12:23,015 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 200 docs
05 Dec 2020 15:12:26,047 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 300 docs
05 Dec 2020 15:12:28,658 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1223563935615475717,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161343369","id":1332435451152654336}}
05 Dec 2020 15:12:29,014 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 400 docs
05 Dec 2020 15:12:29,458 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1606839571,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161343953","id":1332430715753992192}}
05 Dec 2020 15:12:31,075 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 500 docs
05 Dec 2020 15:12:34,126 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 600 docs
05 Dec 2020 15:12:36,998 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 700 docs
05 Dec 2020 15:12:39,467 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 800 docs
05 Dec 2020 15:12:41,275 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 900 docs
05 Dec 2020 15:12:43,202 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,000 docs
05 Dec 2020 15:12:43,204 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 1,000, total skipped docs: 0
05 Dec 2020 15:12:43,205 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     31 docs/second
05 Dec 2020 15:12:43,205 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 32 seconds and processed:
05 Dec 2020 15:12:43,214 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.008 MB/sec sent to index
05 Dec 2020 15:12:43,214 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.259 MB text sent to index
05 Dec 2020 15:12:43,214 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:12:46,037 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,100 docs
05 Dec 2020 15:12:48,076 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,200 docs
05 Dec 2020 15:12:51,002 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,300 docs
05 Dec 2020 15:12:53,068 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,400 docs
05 Dec 2020 15:12:56,068 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,500 docs
05 Dec 2020 15:12:59,652 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,600 docs
05 Dec 2020 15:13:01,950 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,700 docs
05 Dec 2020 15:13:05,721 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,800 docs
05 Dec 2020 15:13:07,067 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,900 docs
05 Dec 2020 15:13:10,276 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,000 docs
05 Dec 2020 15:13:10,277 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 2,000, total skipped docs: 0
05 Dec 2020 15:13:10,278 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     33 docs/second
05 Dec 2020 15:13:10,278 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 59 seconds and processed:
05 Dec 2020 15:13:10,279 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.009 MB/sec sent to index
05 Dec 2020 15:13:10,280 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.522 MB text sent to index
05 Dec 2020 15:13:10,280 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:13:12,385 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,100 docs
05 Dec 2020 15:13:14,956 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,200 docs
05 Dec 2020 15:13:16,298 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,300 docs
05 Dec 2020 15:13:19,037 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,400 docs
05 Dec 2020 15:13:21,337 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,500 docs
05 Dec 2020 15:13:24,038 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,600 docs
05 Dec 2020 15:13:27,043 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,700 docs
05 Dec 2020 15:13:29,084 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,800 docs
05 Dec 2020 15:13:32,057 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,900 docs
05 Dec 2020 15:13:34,004 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,000 docs
05 Dec 2020 15:13:34,005 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 3,000, total skipped docs: 0
05 Dec 2020 15:13:34,005 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     36 docs/second
05 Dec 2020 15:13:34,005 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 83 seconds and processed:
05 Dec 2020 15:13:34,006 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.009 MB/sec sent to index
05 Dec 2020 15:13:34,006 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.788 MB text sent to index
05 Dec 2020 15:13:34,006 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:13:35,514 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":729173028,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161410169","id":1332531534247563264}}
05 Dec 2020 15:13:37,048 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,100 docs
05 Dec 2020 15:13:39,065 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,200 docs
05 Dec 2020 15:13:42,010 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,300 docs
05 Dec 2020 15:13:44,040 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,400 docs
05 Dec 2020 15:13:46,103 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,500 docs
05 Dec 2020 15:13:49,027 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,600 docs
05 Dec 2020 15:13:52,037 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,700 docs
05 Dec 2020 15:13:54,174 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,800 docs
05 Dec 2020 15:13:57,022 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,900 docs
05 Dec 2020 15:14:00,023 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,000 docs
05 Dec 2020 15:14:00,024 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 4,000, total skipped docs: 0
05 Dec 2020 15:14:00,024 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     36 docs/second
05 Dec 2020 15:14:00,025 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 109 seconds and processed:
05 Dec 2020 15:14:00,025 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:14:00,025 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.052 MB text sent to index
05 Dec 2020 15:14:00,026 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:14:02,125 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,100 docs
05 Dec 2020 15:14:05,075 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,200 docs
05 Dec 2020 15:14:06,258 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1307850469755113472,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161440915","id":1332484738406203394}}
05 Dec 2020 15:14:08,061 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,300 docs
05 Dec 2020 15:14:09,517 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":55767644,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161444029","id":1332424915056799745}}
05 Dec 2020 15:14:11,063 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,400 docs
05 Dec 2020 15:14:14,054 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,500 docs
05 Dec 2020 15:14:17,231 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,600 docs
05 Dec 2020 15:14:20,055 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,700 docs
05 Dec 2020 15:14:22,187 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,800 docs
05 Dec 2020 15:14:25,045 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,900 docs
05 Dec 2020 15:14:28,105 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,000 docs
05 Dec 2020 15:14:28,105 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 5,000, total skipped docs: 0
05 Dec 2020 15:14:28,105 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     36 docs/second
05 Dec 2020 15:14:28,106 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 137 seconds and processed:
05 Dec 2020 15:14:28,106 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:14:28,106 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.316 MB text sent to index
05 Dec 2020 15:14:28,107 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:14:30,085 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,100 docs
05 Dec 2020 15:14:33,090 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,200 docs
05 Dec 2020 15:14:36,154 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,300 docs
05 Dec 2020 15:14:37,682 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1223957693901074432,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161472263","id":1332326000768606208}}
05 Dec 2020 15:14:39,032 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,400 docs
05 Dec 2020 15:14:41,116 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,500 docs
05 Dec 2020 15:14:44,059 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,600 docs
05 Dec 2020 15:14:46,999 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,700 docs
05 Dec 2020 15:14:49,071 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,800 docs
05 Dec 2020 15:14:52,221 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,900 docs
05 Dec 2020 15:14:55,308 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,000 docs
05 Dec 2020 15:14:55,308 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 6,000, total skipped docs: 0
05 Dec 2020 15:14:55,311 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     36 docs/second
05 Dec 2020 15:14:55,312 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 164 seconds and processed:
05 Dec 2020 15:14:55,312 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:14:55,312 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.581 MB text sent to index
05 Dec 2020 15:14:55,312 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:14:58,171 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,100 docs
05 Dec 2020 15:15:00,107 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,200 docs
05 Dec 2020 15:15:03,086 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,300 docs
05 Dec 2020 15:15:05,125 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,400 docs
05 Dec 2020 15:15:08,045 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,500 docs
05 Dec 2020 15:15:10,054 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,600 docs
05 Dec 2020 15:15:13,031 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,700 docs
05 Dec 2020 15:15:15,143 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,800 docs
05 Dec 2020 15:15:17,045 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,900 docs
05 Dec 2020 15:15:20,065 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,000 docs
05 Dec 2020 15:15:20,065 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 7,000, total skipped docs: 0
05 Dec 2020 15:15:20,066 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:15:20,066 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 189 seconds and processed:
05 Dec 2020 15:15:20,066 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:15:20,066 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.845 MB text sent to index
05 Dec 2020 15:15:20,067 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:15:22,122 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,100 docs
05 Dec 2020 15:15:25,069 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,200 docs
05 Dec 2020 15:15:28,040 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,300 docs
05 Dec 2020 15:15:30,193 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,400 docs
05 Dec 2020 15:15:32,469 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,500 docs
05 Dec 2020 15:15:35,587 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,600 docs
05 Dec 2020 15:15:38,134 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,700 docs
05 Dec 2020 15:15:40,334 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,800 docs
05 Dec 2020 15:15:42,498 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,900 docs
05 Dec 2020 15:15:45,011 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,000 docs
05 Dec 2020 15:15:45,011 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 8,000, total skipped docs: 0
05 Dec 2020 15:15:45,011 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:15:45,012 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 214 seconds and processed:
05 Dec 2020 15:15:45,012 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:15:45,012 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.105 MB text sent to index
05 Dec 2020 15:15:45,013 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:15:47,071 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,100 docs
05 Dec 2020 15:15:50,172 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,200 docs
05 Dec 2020 15:15:52,287 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,300 docs
05 Dec 2020 15:15:55,045 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,400 docs
05 Dec 2020 15:15:59,014 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,500 docs
05 Dec 2020 15:16:00,144 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,600 docs
05 Dec 2020 15:16:03,105 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,700 docs
05 Dec 2020 15:16:06,063 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,800 docs
05 Dec 2020 15:16:09,239 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,900 docs
05 Dec 2020 15:16:11,260 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1298575531668111362,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161565934","id":1332711675418521600}}
05 Dec 2020 15:16:12,046 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,000 docs
05 Dec 2020 15:16:12,047 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 9,000, total skipped docs: 0
05 Dec 2020 15:16:12,047 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:16:12,047 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 241 seconds and processed:
05 Dec 2020 15:16:12,048 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:16:12,048 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.37 MB text sent to index
05 Dec 2020 15:16:12,048 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:16:15,095 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,100 docs
05 Dec 2020 15:16:17,040 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,200 docs
05 Dec 2020 15:16:20,044 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,300 docs
05 Dec 2020 15:16:22,338 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,400 docs
05 Dec 2020 15:16:25,045 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,500 docs
05 Dec 2020 15:16:27,238 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,600 docs
05 Dec 2020 15:16:30,069 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,700 docs
05 Dec 2020 15:16:33,191 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,800 docs
05 Dec 2020 15:16:36,062 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,900 docs
05 Dec 2020 15:16:38,983 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,000 docs
05 Dec 2020 15:16:38,983 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 10,000, total skipped docs: 0
05 Dec 2020 15:16:38,983 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:16:38,983 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 268 seconds and processed:
05 Dec 2020 15:16:38,983 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:16:38,984 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.634 MB text sent to index
05 Dec 2020 15:16:38,984 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:16:41,030 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,100 docs
05 Dec 2020 15:16:43,015 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,200 docs
05 Dec 2020 15:16:46,128 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,300 docs
05 Dec 2020 15:16:49,003 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,400 docs
05 Dec 2020 15:16:51,998 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,500 docs
05 Dec 2020 15:16:54,002 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,600 docs
05 Dec 2020 15:16:56,056 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,700 docs
05 Dec 2020 15:16:58,996 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,800 docs
05 Dec 2020 15:17:01,053 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,900 docs
05 Dec 2020 15:17:04,244 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,000 docs
05 Dec 2020 15:17:04,244 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 11,000, total skipped docs: 0
05 Dec 2020 15:17:04,246 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:17:04,247 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 293 seconds and processed:
05 Dec 2020 15:17:04,247 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:17:04,247 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.9 MB text sent to index
05 Dec 2020 15:17:04,248 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:17:07,041 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,100 docs
05 Dec 2020 15:17:09,104 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,200 docs
05 Dec 2020 15:17:11,753 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,300 docs
05 Dec 2020 15:17:14,018 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,400 docs
05 Dec 2020 15:17:16,112 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,500 docs
05 Dec 2020 15:17:16,423 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1157417137176240129,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161631100","id":1332735482283905037}}
05 Dec 2020 15:17:19,280 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,600 docs
05 Dec 2020 15:17:22,036 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,700 docs
05 Dec 2020 15:17:22,773 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1330866241981067265,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161637219","id":1332374612764745728}}
05 Dec 2020 15:17:24,944 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,800 docs
05 Dec 2020 15:17:27,173 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,900 docs
05 Dec 2020 15:17:30,014 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,000 docs
05 Dec 2020 15:17:30,016 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 12,000, total skipped docs: 0
05 Dec 2020 15:17:30,016 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:17:30,017 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 319 seconds and processed:
05 Dec 2020 15:17:30,018 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:17:30,021 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.164 MB text sent to index
05 Dec 2020 15:17:30,021 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:17:32,046 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,100 docs
05 Dec 2020 15:17:34,992 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,200 docs
05 Dec 2020 15:17:37,136 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,300 docs
05 Dec 2020 15:17:40,044 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,400 docs
05 Dec 2020 15:17:41,978 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,500 docs
05 Dec 2020 15:17:45,034 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,600 docs
05 Dec 2020 15:17:48,056 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,700 docs
05 Dec 2020 15:17:50,996 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,800 docs
05 Dec 2020 15:17:53,019 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,900 docs
05 Dec 2020 15:17:56,037 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,000 docs
05 Dec 2020 15:17:56,037 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 13,000, total skipped docs: 0
05 Dec 2020 15:17:56,037 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:17:56,038 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 345 seconds and processed:
05 Dec 2020 15:17:56,038 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:17:56,038 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.428 MB text sent to index
05 Dec 2020 15:17:56,038 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:17:58,284 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,100 docs
05 Dec 2020 15:18:01,157 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,200 docs
05 Dec 2020 15:18:02,951 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,300 docs
05 Dec 2020 15:18:06,909 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,400 docs
05 Dec 2020 15:18:08,949 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,500 docs
05 Dec 2020 15:18:11,868 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,600 docs
05 Dec 2020 15:18:13,902 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,700 docs
05 Dec 2020 15:18:16,858 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,800 docs
05 Dec 2020 15:18:18,995 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,900 docs
05 Dec 2020 15:18:21,948 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,000 docs
05 Dec 2020 15:18:21,949 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 14,000, total skipped docs: 0
05 Dec 2020 15:18:21,949 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:18:21,949 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 371 seconds and processed:
05 Dec 2020 15:18:21,949 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:18:21,949 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.694 MB text sent to index
05 Dec 2020 15:18:21,950 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:18:23,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,100 docs
05 Dec 2020 15:18:26,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,200 docs
05 Dec 2020 15:18:27,843 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":864241286387290117,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161702689","id":1332788024317456384}}
05 Dec 2020 15:18:29,874 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,300 docs
05 Dec 2020 15:18:33,138 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,400 docs
05 Dec 2020 15:18:34,884 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,500 docs
05 Dec 2020 15:18:37,858 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,600 docs
05 Dec 2020 15:18:39,940 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,700 docs
05 Dec 2020 15:18:42,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,800 docs
05 Dec 2020 15:18:44,855 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,900 docs
05 Dec 2020 15:18:47,851 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,000 docs
05 Dec 2020 15:18:47,851 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 15,000, total skipped docs: 0
05 Dec 2020 15:18:47,853 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:18:47,854 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 397 seconds and processed:
05 Dec 2020 15:18:47,854 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:18:47,855 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.962 MB text sent to index
05 Dec 2020 15:18:47,856 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:18:49,875 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,100 docs
05 Dec 2020 15:18:52,642 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":932315484917256192,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161727416","id":1332740221834846214}}
05 Dec 2020 15:18:52,984 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,200 docs
05 Dec 2020 15:18:55,859 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,300 docs
05 Dec 2020 15:18:57,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,400 docs
05 Dec 2020 15:19:00,854 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,500 docs
05 Dec 2020 15:19:03,885 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,600 docs
05 Dec 2020 15:19:07,055 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,700 docs
05 Dec 2020 15:19:08,890 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,800 docs
05 Dec 2020 15:19:10,880 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":562056982,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161745570","id":1330645817137491969}}
05 Dec 2020 15:19:11,852 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,900 docs
05 Dec 2020 15:19:14,831 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,000 docs
05 Dec 2020 15:19:14,831 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 16,000, total skipped docs: 0
05 Dec 2020 15:19:14,832 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:19:14,832 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 424 seconds and processed:
05 Dec 2020 15:19:14,832 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:19:14,832 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.225 MB text sent to index
05 Dec 2020 15:19:14,832 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:19:16,295 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1205635335876681732,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161751150","id":1332804285634142210}}
05 Dec 2020 15:19:16,844 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,100 docs
05 Dec 2020 15:19:18,895 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,200 docs
05 Dec 2020 15:19:21,846 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,300 docs
05 Dec 2020 15:19:24,844 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,400 docs
05 Dec 2020 15:19:26,928 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,500 docs
05 Dec 2020 15:19:28,878 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,600 docs
05 Dec 2020 15:19:31,841 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,700 docs
05 Dec 2020 15:19:33,880 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,800 docs
05 Dec 2020 15:19:34,330 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1211353702692343808,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161769196","id":1332823998883790850}}
05 Dec 2020 15:19:37,155 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,900 docs
05 Dec 2020 15:19:39,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,000 docs
05 Dec 2020 15:19:39,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 17,000, total skipped docs: 0
05 Dec 2020 15:19:39,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:19:39,850 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 449 seconds and processed:
05 Dec 2020 15:19:39,850 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:19:39,850 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.486 MB text sent to index
05 Dec 2020 15:19:39,850 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:19:42,826 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,100 docs
05 Dec 2020 15:19:45,829 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,200 docs
05 Dec 2020 15:19:48,038 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,300 docs
05 Dec 2020 15:19:50,874 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,400 docs
05 Dec 2020 15:19:53,129 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,500 docs
05 Dec 2020 15:19:55,827 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,600 docs
05 Dec 2020 15:19:58,003 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,700 docs
05 Dec 2020 15:20:02,075 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,800 docs
05 Dec 2020 15:20:03,884 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,900 docs
05 Dec 2020 15:20:06,869 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,000 docs
05 Dec 2020 15:20:06,869 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 18,000, total skipped docs: 0
05 Dec 2020 15:20:06,869 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:20:06,870 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 476 seconds and processed:
05 Dec 2020 15:20:06,870 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:20:06,870 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.747 MB text sent to index
05 Dec 2020 15:20:06,870 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:20:08,860 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,100 docs
05 Dec 2020 15:20:11,859 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,200 docs
05 Dec 2020 15:20:14,834 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,300 docs
05 Dec 2020 15:20:16,850 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,400 docs
05 Dec 2020 15:20:19,054 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,500 docs
05 Dec 2020 15:20:21,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,600 docs
05 Dec 2020 15:20:23,847 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,700 docs
05 Dec 2020 15:20:26,826 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,800 docs
05 Dec 2020 15:20:28,957 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,900 docs
05 Dec 2020 15:20:31,944 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,000 docs
05 Dec 2020 15:20:31,944 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 19,000, total skipped docs: 0
05 Dec 2020 15:20:31,945 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:20:31,945 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 501 seconds and processed:
05 Dec 2020 15:20:31,945 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:20:31,946 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     5.011 MB text sent to index
05 Dec 2020 15:20:31,946 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:20:33,395 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1320011826638172160,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161828272","id":1320028691531849728}}
05 Dec 2020 15:20:34,869 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,100 docs
05 Dec 2020 15:20:37,841 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,200 docs
05 Dec 2020 15:20:41,111 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,300 docs
05 Dec 2020 15:20:41,182 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":4822274159,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161835857","id":1242325783160348674}}
05 Dec 2020 15:20:42,895 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,400 docs
05 Dec 2020 15:20:45,002 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,500 docs
05 Dec 2020 15:20:47,931 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,600 docs
05 Dec 2020 15:20:50,862 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,700 docs
05 Dec 2020 15:20:53,868 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,800 docs
05 Dec 2020 15:20:56,867 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,900 docs
05 Dec 2020 15:20:59,848 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,000 docs
05 Dec 2020 15:20:59,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 20,000, total skipped docs: 0
05 Dec 2020 15:20:59,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:20:59,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 529 seconds and processed:
05 Dec 2020 15:20:59,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:20:59,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     5.275 MB text sent to index
05 Dec 2020 15:20:59,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:21:02,866 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,100 docs
05 Dec 2020 15:21:04,883 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,200 docs
05 Dec 2020 15:21:07,836 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,300 docs
05 Dec 2020 15:21:10,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,400 docs
05 Dec 2020 15:21:12,883 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,500 docs
05 Dec 2020 15:21:15,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,600 docs
05 Dec 2020 15:21:18,815 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,700 docs
05 Dec 2020 15:21:21,145 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,800 docs
05 Dec 2020 15:21:24,062 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,900 docs
05 Dec 2020 15:21:25,990 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,000 docs
05 Dec 2020 15:21:25,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 21,000, total skipped docs: 0
05 Dec 2020 15:21:25,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:21:25,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 555 seconds and processed:
05 Dec 2020 15:21:25,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:21:25,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     5.54 MB text sent to index
05 Dec 2020 15:21:25,992 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:21:28,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,100 docs
05 Dec 2020 15:21:30,853 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,200 docs
05 Dec 2020 15:21:33,847 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,300 docs
05 Dec 2020 15:21:35,363 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1332458469056786434,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607161890243","id":1333043801368256513}}
05 Dec 2020 15:21:36,003 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,400 docs
05 Dec 2020 15:21:39,818 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,500 docs
05 Dec 2020 15:21:41,878 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,600 docs
05 Dec 2020 15:21:44,854 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,700 docs
05 Dec 2020 15:21:46,863 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,800 docs
05 Dec 2020 15:21:49,854 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,900 docs
05 Dec 2020 15:21:51,945 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,000 docs
05 Dec 2020 15:21:51,945 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 22,000, total skipped docs: 0
05 Dec 2020 15:21:51,945 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:21:51,945 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 581 seconds and processed:
05 Dec 2020 15:21:51,945 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:21:51,946 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     5.805 MB text sent to index
05 Dec 2020 15:21:51,946 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:21:54,898 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,100 docs
05 Dec 2020 15:21:57,001 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,200 docs
05 Dec 2020 15:21:59,858 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,300 docs
05 Dec 2020 15:22:01,898 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,400 docs
05 Dec 2020 15:22:04,863 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,500 docs
05 Dec 2020 15:22:07,016 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,600 docs
05 Dec 2020 15:22:09,826 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,700 docs
05 Dec 2020 15:22:12,814 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,800 docs
05 Dec 2020 15:22:14,847 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,900 docs
05 Dec 2020 15:22:17,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,000 docs
05 Dec 2020 15:22:17,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 23,000, total skipped docs: 0
05 Dec 2020 15:22:17,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:22:17,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 607 seconds and processed:
05 Dec 2020 15:22:17,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:22:17,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     6.071 MB text sent to index
05 Dec 2020 15:22:17,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:22:20,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,100 docs
05 Dec 2020 15:22:22,914 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,200 docs
05 Dec 2020 15:22:25,846 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,300 docs
05 Dec 2020 15:22:27,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,400 docs
05 Dec 2020 15:22:30,929 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,500 docs
05 Dec 2020 15:22:34,119 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,600 docs
05 Dec 2020 15:22:36,827 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,700 docs
05 Dec 2020 15:22:38,901 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,800 docs
05 Dec 2020 15:22:41,812 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,900 docs
05 Dec 2020 15:22:43,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,000 docs
05 Dec 2020 15:22:43,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 24,000, total skipped docs: 0
05 Dec 2020 15:22:43,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:22:43,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 633 seconds and processed:
05 Dec 2020 15:22:43,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:22:43,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     6.336 MB text sent to index
05 Dec 2020 15:22:43,889 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:22:46,864 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,100 docs
05 Dec 2020 15:22:48,850 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,200 docs
05 Dec 2020 15:22:52,006 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,300 docs
05 Dec 2020 15:22:53,938 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,400 docs
05 Dec 2020 15:22:57,040 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,500 docs
05 Dec 2020 15:22:58,927 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,600 docs
05 Dec 2020 15:23:01,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,700 docs
05 Dec 2020 15:23:03,914 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,800 docs
05 Dec 2020 15:23:06,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,900 docs
05 Dec 2020 15:23:09,042 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,000 docs
05 Dec 2020 15:23:09,042 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 25,000, total skipped docs: 0
05 Dec 2020 15:23:09,042 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     37 docs/second
05 Dec 2020 15:23:09,042 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 658 seconds and processed:
05 Dec 2020 15:23:09,042 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:23:09,042 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     6.599 MB text sent to index
05 Dec 2020 15:23:09,042 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:23:11,803 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,100 docs
05 Dec 2020 15:23:13,994 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,200 docs
05 Dec 2020 15:23:16,943 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,300 docs
05 Dec 2020 15:23:19,041 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,400 docs
05 Dec 2020 15:23:21,885 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,500 docs
05 Dec 2020 15:23:24,144 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,600 docs
05 Dec 2020 15:23:26,870 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,700 docs
05 Dec 2020 15:23:29,806 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,800 docs
05 Dec 2020 15:23:31,998 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,900 docs
05 Dec 2020 15:23:34,092 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,000 docs
05 Dec 2020 15:23:34,093 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 26,000, total skipped docs: 0
05 Dec 2020 15:23:34,093 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     38 docs/second
05 Dec 2020 15:23:34,093 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 683 seconds and processed:
05 Dec 2020 15:23:34,093 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:23:34,093 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     6.862 MB text sent to index
05 Dec 2020 15:23:34,093 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:23:36,963 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,100 docs
05 Dec 2020 15:23:39,847 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,200 docs
05 Dec 2020 15:23:42,141 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,300 docs
05 Dec 2020 15:23:44,953 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,400 docs
05 Dec 2020 15:23:46,376 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":799281762576846848,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607162021246","id":1332403020785725445}}
05 Dec 2020 15:23:47,025 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,500 docs
05 Dec 2020 15:23:49,967 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,600 docs
05 Dec 2020 15:23:53,183 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,700 docs
05 Dec 2020 15:23:55,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,800 docs
05 Dec 2020 15:23:59,024 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,900 docs
05 Dec 2020 15:24:01,244 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,000 docs
05 Dec 2020 15:24:01,245 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 27,000, total skipped docs: 0
05 Dec 2020 15:24:01,245 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     38 docs/second
05 Dec 2020 15:24:01,245 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 710 seconds and processed:
05 Dec 2020 15:24:01,245 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.01 MB/sec sent to index
05 Dec 2020 15:24:01,245 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     7.122 MB text sent to index
05 Dec 2020 15:24:01,245 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 15:24:04,107 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,100 docs
05 Dec 2020 15:24:07,648 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,200 docs
05 Dec 2020 16:43:13,599 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
05 Dec 2020 16:43:13,641 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: FileChannel stopped
05 Dec 2020 16:43:13,641 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.start.time == 1607161330558
05 Dec 2020 16:43:13,642 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.stop.time == 1607166793641
05 Dec 2020 16:43:13,642 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.capacity == 10000
05 Dec 2020 16:43:13,642 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.current.size == 601
05 Dec 2020 16:43:13,642 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.put.attempt == 601
05 Dec 2020 16:43:13,642 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.put.success == 601
05 Dec 2020 16:43:13,642 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.take.attempt == 2
05 Dec 2020 16:43:13,642 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.take.success == 0
05 Dec 2020 16:43:13,642 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
05 Dec 2020 16:43:13,643 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 16:43:13,689 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 16:43:13,689 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.HDFSEventSink.stop:492)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData
05 Dec 2020 16:43:13,690 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing null
05 Dec 2020 16:43:13,706 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.BucketWriter.close:378)  - HDFSWriter is already closed: null
05 Dec 2020 16:43:13,706 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 16:43:13,706 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607161330570
05 Dec 2020 16:43:13,706 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607166793706
05 Dec 2020 16:43:13,706 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 16:43:13,706 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 1
05 Dec 2020 16:43:13,706 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
05 Dec 2020 16:43:13,706 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 16:43:13,709 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
05 Dec 2020 16:43:13,709 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
05 Dec 2020 16:43:13,710 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
05 Dec 2020 16:43:13,710 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 16:43:26,594 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
05 Dec 2020 16:43:26,607 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:/home/tanishka/Downloads/Flume/apache-flume-1.6.0-bin/conf/twitter.conf
05 Dec 2020 16:43:26,642 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 16:43:26,643 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 16:43:26,643 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 16:43:26,644 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 16:43:26,646 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 16:43:26,646 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 16:43:26,647 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 16:43:26,648 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 16:43:26,648 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 16:43:26,676 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 16:43:26,676 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 16:43:26,685 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel FileChannel type memory
05 Dec 2020 16:43:26,695 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel FileChannel
05 Dec 2020 16:43:26,697 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 16:43:26,707 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        'qM5WhxIzaHRRvlqbcol7YhB1o'
05 Dec 2020 16:43:26,708 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     'dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie'
05 Dec 2020 16:43:26,708 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        '1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo'
05 Dec 2020 16:43:26,708 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: 'bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz'
05 Dec 2020 16:43:27,050 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 16:43:27,077 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel FileChannel connected to [Twitter, HDFS]
05 Dec 2020 16:43:27,089 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@4336036c counterGroup:{ name:null counters:{} } }} channels:{FileChannel=org.apache.flume.channel.MemoryChannel{name: FileChannel}} }
05 Dec 2020 16:43:27,107 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel FileChannel
05 Dec 2020 16:43:27,697 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: FileChannel: Successfully registered new MBean.
05 Dec 2020 16:43:27,697 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: FileChannel started
05 Dec 2020 16:43:27,698 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 16:43:27,703 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 16:43:27,711 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 16:43:27,712 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 16:43:27,718 INFO  [lifecycleSupervisor-1-4] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 16:43:27,720 INFO  [lifecycleSupervisor-1-4] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 16:43:27,722 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 16:43:30,936 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Connection established.
05 Dec 2020 16:43:30,938 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Receiving status stream.
05 Dec 2020 16:43:31,786 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.HDFSDataStream.configure:58)  - Serializer = TEXT, UseRawLocalFileSystem = false
05 Dec 2020 16:43:31,956 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.HDFSEventSink.process:459)  - process failed
java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:1380)
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:1361)
	at org.apache.hadoop.conf.Configuration.setBoolean(Configuration.java:1703)
	at org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:209)
	at org.apache.flume.sink.hdfs.BucketWriter.append(BucketWriter.java:514)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:418)
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:748)
05 Dec 2020 16:43:33,011 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 100 docs
05 Dec 2020 16:43:34,953 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 200 docs
05 Dec 2020 16:43:37,057 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 300 docs
05 Dec 2020 16:43:38,933 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 400 docs
05 Dec 2020 16:43:40,889 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 500 docs
05 Dec 2020 16:43:42,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 600 docs
05 Dec 2020 16:43:44,885 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 700 docs
05 Dec 2020 16:43:46,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 800 docs
05 Dec 2020 16:43:48,890 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 900 docs
05 Dec 2020 16:43:50,881 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,000 docs
05 Dec 2020 16:43:50,881 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 1,000, total skipped docs: 0
05 Dec 2020 16:43:50,881 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     43 docs/second
05 Dec 2020 16:43:50,883 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 23 seconds and processed:
05 Dec 2020 16:43:50,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.011 MB/sec sent to index
05 Dec 2020 16:43:50,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.259 MB text sent to index
05 Dec 2020 16:43:50,918 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:43:52,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,100 docs
05 Dec 2020 16:43:54,054 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,200 docs
05 Dec 2020 16:43:54,261 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":573022858,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607166829090","id":1283789070292877318}}
05 Dec 2020 16:43:56,046 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,300 docs
05 Dec 2020 16:43:57,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,400 docs
05 Dec 2020 16:43:59,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,500 docs
05 Dec 2020 16:44:01,915 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,600 docs
05 Dec 2020 16:44:03,926 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,700 docs
05 Dec 2020 16:44:05,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,800 docs
05 Dec 2020 16:44:08,868 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,900 docs
05 Dec 2020 16:44:09,932 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,000 docs
05 Dec 2020 16:44:09,932 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 2,000, total skipped docs: 0
05 Dec 2020 16:44:09,933 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 16:44:09,933 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 42 seconds and processed:
05 Dec 2020 16:44:09,933 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.012 MB/sec sent to index
05 Dec 2020 16:44:09,933 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.521 MB text sent to index
05 Dec 2020 16:44:09,933 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:44:11,914 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,100 docs
05 Dec 2020 16:44:12,523 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":465970561,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607166847352","id":1058398632163053568}}
05 Dec 2020 16:44:13,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,200 docs
05 Dec 2020 16:44:15,964 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,300 docs
05 Dec 2020 16:44:18,868 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,400 docs
05 Dec 2020 16:44:20,864 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,500 docs
05 Dec 2020 16:44:22,929 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,600 docs
05 Dec 2020 16:44:24,866 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,700 docs
05 Dec 2020 16:44:26,899 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,800 docs
05 Dec 2020 16:44:28,977 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,900 docs
05 Dec 2020 16:44:31,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,000 docs
05 Dec 2020 16:44:31,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 3,000, total skipped docs: 0
05 Dec 2020 16:44:31,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     46 docs/second
05 Dec 2020 16:44:31,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 64 seconds and processed:
05 Dec 2020 16:44:31,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.012 MB/sec sent to index
05 Dec 2020 16:44:31,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.783 MB text sent to index
05 Dec 2020 16:44:31,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:44:32,686 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":848603191,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607166867511","id":1079499621959958528}}
05 Dec 2020 16:44:33,878 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,100 docs
05 Dec 2020 16:44:35,867 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,200 docs
05 Dec 2020 16:44:37,866 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,300 docs
05 Dec 2020 16:44:39,875 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,400 docs
05 Dec 2020 16:44:41,890 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,500 docs
05 Dec 2020 16:44:43,903 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,600 docs
05 Dec 2020 16:44:46,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,700 docs
05 Dec 2020 16:44:48,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,800 docs
05 Dec 2020 16:44:50,874 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,900 docs
05 Dec 2020 16:44:52,013 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,000 docs
05 Dec 2020 16:44:52,015 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 4,000, total skipped docs: 0
05 Dec 2020 16:44:52,015 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 16:44:52,015 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 84 seconds and processed:
05 Dec 2020 16:44:52,016 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.012 MB/sec sent to index
05 Dec 2020 16:44:52,017 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.047 MB text sent to index
05 Dec 2020 16:44:52,017 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:44:54,870 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,100 docs
05 Dec 2020 16:44:56,885 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,200 docs
05 Dec 2020 16:44:58,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,300 docs
05 Dec 2020 16:45:00,886 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,400 docs
05 Dec 2020 16:45:03,069 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,500 docs
05 Dec 2020 16:45:05,874 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,600 docs
05 Dec 2020 16:45:07,885 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,700 docs
05 Dec 2020 16:45:09,892 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,800 docs
05 Dec 2020 16:45:11,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,900 docs
05 Dec 2020 16:45:13,908 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,000 docs
05 Dec 2020 16:45:13,908 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 5,000, total skipped docs: 0
05 Dec 2020 16:45:13,909 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 16:45:13,909 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 106 seconds and processed:
05 Dec 2020 16:45:13,909 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.012 MB/sec sent to index
05 Dec 2020 16:45:13,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.311 MB text sent to index
05 Dec 2020 16:45:13,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:45:15,970 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,100 docs
05 Dec 2020 16:45:17,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,200 docs
05 Dec 2020 16:45:19,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,300 docs
05 Dec 2020 16:45:21,947 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,400 docs
05 Dec 2020 16:45:23,117 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":2522030756,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607166917943","id":1141326812846292992}}
05 Dec 2020 16:45:24,865 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,500 docs
05 Dec 2020 16:45:26,875 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,600 docs
05 Dec 2020 16:45:28,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,700 docs
05 Dec 2020 16:45:30,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,800 docs
05 Dec 2020 16:45:33,863 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,900 docs
05 Dec 2020 16:45:35,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,000 docs
05 Dec 2020 16:45:35,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 6,000, total skipped docs: 0
05 Dec 2020 16:45:35,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     46 docs/second
05 Dec 2020 16:45:35,878 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 128 seconds and processed:
05 Dec 2020 16:45:35,878 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.012 MB/sec sent to index
05 Dec 2020 16:45:35,878 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.578 MB text sent to index
05 Dec 2020 16:45:35,878 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:45:37,891 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,100 docs
05 Dec 2020 16:45:39,875 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,200 docs
05 Dec 2020 16:45:41,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,300 docs
05 Dec 2020 16:45:43,978 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,400 docs
05 Dec 2020 16:45:46,868 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,500 docs
05 Dec 2020 16:45:48,869 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,600 docs
05 Dec 2020 16:45:50,364 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,700 docs
05 Dec 2020 16:45:51,902 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,800 docs
05 Dec 2020 16:45:54,859 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,900 docs
05 Dec 2020 16:45:56,869 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,000 docs
05 Dec 2020 16:45:56,869 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 7,000, total skipped docs: 0
05 Dec 2020 16:45:56,870 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     46 docs/second
05 Dec 2020 16:45:56,870 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 149 seconds and processed:
05 Dec 2020 16:45:56,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.012 MB/sec sent to index
05 Dec 2020 16:45:56,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.838 MB text sent to index
05 Dec 2020 16:45:56,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:45:58,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,100 docs
05 Dec 2020 16:46:00,889 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,200 docs
05 Dec 2020 16:46:02,880 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,300 docs
05 Dec 2020 16:46:04,879 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,400 docs
05 Dec 2020 16:46:06,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,500 docs
05 Dec 2020 16:46:08,995 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,600 docs
05 Dec 2020 16:46:10,928 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,700 docs
05 Dec 2020 16:46:13,875 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,800 docs
05 Dec 2020 16:46:15,880 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,900 docs
05 Dec 2020 16:46:17,876 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,000 docs
05 Dec 2020 16:46:17,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 8,000, total skipped docs: 0
05 Dec 2020 16:46:17,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 16:46:17,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 170 seconds and processed:
05 Dec 2020 16:46:17,878 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.012 MB/sec sent to index
05 Dec 2020 16:46:17,878 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.103 MB text sent to index
05 Dec 2020 16:46:17,879 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:46:19,046 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,100 docs
05 Dec 2020 16:46:20,882 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,200 docs
05 Dec 2020 16:46:22,907 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,300 docs
05 Dec 2020 16:46:24,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,400 docs
05 Dec 2020 16:46:26,926 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,500 docs
05 Dec 2020 16:46:28,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,600 docs
05 Dec 2020 16:46:30,921 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,700 docs
05 Dec 2020 16:46:32,889 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,800 docs
05 Dec 2020 16:46:34,889 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,900 docs
05 Dec 2020 16:46:36,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,000 docs
05 Dec 2020 16:46:36,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 9,000, total skipped docs: 0
05 Dec 2020 16:46:36,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 16:46:36,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 189 seconds and processed:
05 Dec 2020 16:46:36,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:46:36,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.364 MB text sent to index
05 Dec 2020 16:46:36,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:46:39,865 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,100 docs
05 Dec 2020 16:46:41,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,200 docs
05 Dec 2020 16:46:43,881 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,300 docs
05 Dec 2020 16:46:45,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,400 docs
05 Dec 2020 16:46:47,879 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,500 docs
05 Dec 2020 16:46:49,879 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,600 docs
05 Dec 2020 16:46:51,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,700 docs
05 Dec 2020 16:46:53,914 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,800 docs
05 Dec 2020 16:46:55,895 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,900 docs
05 Dec 2020 16:46:57,919 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,000 docs
05 Dec 2020 16:46:57,920 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 10,000, total skipped docs: 0
05 Dec 2020 16:46:57,920 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 16:46:57,920 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 210 seconds and processed:
05 Dec 2020 16:46:57,920 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.012 MB/sec sent to index
05 Dec 2020 16:46:57,921 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.624 MB text sent to index
05 Dec 2020 16:46:57,921 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:46:59,932 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,100 docs
05 Dec 2020 16:47:01,910 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,200 docs
05 Dec 2020 16:47:03,954 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,300 docs
05 Dec 2020 16:47:06,869 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,400 docs
05 Dec 2020 16:47:07,910 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,500 docs
05 Dec 2020 16:47:09,898 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,600 docs
05 Dec 2020 16:47:12,111 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,700 docs
05 Dec 2020 16:47:14,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,800 docs
05 Dec 2020 16:47:16,879 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,900 docs
05 Dec 2020 16:47:17,931 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,000 docs
05 Dec 2020 16:47:17,931 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 11,000, total skipped docs: 0
05 Dec 2020 16:47:17,932 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 16:47:17,932 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 230 seconds and processed:
05 Dec 2020 16:47:17,933 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:47:17,942 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.88 MB text sent to index
05 Dec 2020 16:47:17,942 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:47:19,913 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,100 docs
05 Dec 2020 16:47:21,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,200 docs
05 Dec 2020 16:47:23,898 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,300 docs
05 Dec 2020 16:47:25,895 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,400 docs
05 Dec 2020 16:47:28,013 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,500 docs
05 Dec 2020 16:47:29,899 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,600 docs
05 Dec 2020 16:47:31,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,700 docs
05 Dec 2020 16:47:33,891 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,800 docs
05 Dec 2020 16:47:35,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,900 docs
05 Dec 2020 16:47:38,866 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,000 docs
05 Dec 2020 16:47:38,866 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 12,000, total skipped docs: 0
05 Dec 2020 16:47:38,867 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 16:47:38,867 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 251 seconds and processed:
05 Dec 2020 16:47:38,867 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:47:38,867 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.143 MB text sent to index
05 Dec 2020 16:47:38,868 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:47:40,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,100 docs
05 Dec 2020 16:47:41,806 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":963949916144971777,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607167056632","id":1329525795363184640}}
05 Dec 2020 16:47:42,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,200 docs
05 Dec 2020 16:47:44,884 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,300 docs
05 Dec 2020 16:47:45,129 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":744567130310443008,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607167059960","id":1329074916042309633}}
05 Dec 2020 16:47:46,874 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,400 docs
05 Dec 2020 16:47:48,918 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,500 docs
05 Dec 2020 16:47:50,922 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,600 docs
05 Dec 2020 16:47:52,907 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,700 docs
05 Dec 2020 16:47:54,912 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,800 docs
05 Dec 2020 16:47:57,093 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,900 docs
05 Dec 2020 16:47:59,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,000 docs
05 Dec 2020 16:47:59,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 13,000, total skipped docs: 0
05 Dec 2020 16:47:59,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 16:47:59,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 272 seconds and processed:
05 Dec 2020 16:47:59,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:47:59,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.4 MB text sent to index
05 Dec 2020 16:47:59,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:48:01,882 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,100 docs
05 Dec 2020 16:48:03,886 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,200 docs
05 Dec 2020 16:48:05,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,300 docs
05 Dec 2020 16:48:07,876 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,400 docs
05 Dec 2020 16:48:09,889 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,500 docs
05 Dec 2020 16:48:11,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,600 docs
05 Dec 2020 16:48:12,954 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,700 docs
05 Dec 2020 16:48:14,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,800 docs
05 Dec 2020 16:48:17,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,900 docs
05 Dec 2020 16:48:19,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,000 docs
05 Dec 2020 16:48:19,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 14,000, total skipped docs: 0
05 Dec 2020 16:48:19,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 16:48:19,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 292 seconds and processed:
05 Dec 2020 16:48:19,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:48:19,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.659 MB text sent to index
05 Dec 2020 16:48:19,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:48:20,919 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,100 docs
05 Dec 2020 16:48:22,892 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,200 docs
05 Dec 2020 16:48:24,725 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":848890830291185664,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607167099552","id":1329094616700710912}}
05 Dec 2020 16:48:25,899 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,300 docs
05 Dec 2020 16:48:27,881 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,400 docs
05 Dec 2020 16:48:29,929 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,500 docs
05 Dec 2020 16:48:31,921 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,600 docs
05 Dec 2020 16:48:33,929 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,700 docs
05 Dec 2020 16:48:35,004 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":3035520941,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607167109714","id":1308153547331121154}}
05 Dec 2020 16:48:35,973 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,800 docs
05 Dec 2020 16:48:37,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,900 docs
05 Dec 2020 16:48:39,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,000 docs
05 Dec 2020 16:48:39,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 15,000, total skipped docs: 0
05 Dec 2020 16:48:39,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:48:39,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 312 seconds and processed:
05 Dec 2020 16:48:39,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:48:39,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.914 MB text sent to index
05 Dec 2020 16:48:39,874 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:48:42,162 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,100 docs
05 Dec 2020 16:48:43,912 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,200 docs
05 Dec 2020 16:48:44,928 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,300 docs
05 Dec 2020 16:48:47,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,400 docs
05 Dec 2020 16:48:49,876 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,500 docs
05 Dec 2020 16:48:51,899 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,600 docs
05 Dec 2020 16:48:53,938 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,700 docs
05 Dec 2020 16:48:56,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,800 docs
05 Dec 2020 16:48:57,002 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":841079496505741312,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607167131751","id":1270825562949517316}}
05 Dec 2020 16:48:58,868 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,900 docs
05 Dec 2020 16:48:59,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,000 docs
05 Dec 2020 16:48:59,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 16,000, total skipped docs: 0
05 Dec 2020 16:48:59,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:48:59,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 332 seconds and processed:
05 Dec 2020 16:48:59,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:48:59,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.176 MB text sent to index
05 Dec 2020 16:48:59,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:49:01,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,100 docs
05 Dec 2020 16:49:03,916 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,200 docs
05 Dec 2020 16:49:05,907 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,300 docs
05 Dec 2020 16:49:07,890 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,400 docs
05 Dec 2020 16:49:09,932 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,500 docs
05 Dec 2020 16:49:11,884 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,600 docs
05 Dec 2020 16:49:13,919 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,700 docs
05 Dec 2020 16:49:15,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,800 docs
05 Dec 2020 16:49:17,947 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,900 docs
05 Dec 2020 16:49:20,862 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,000 docs
05 Dec 2020 16:49:20,863 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 17,000, total skipped docs: 0
05 Dec 2020 16:49:20,863 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:49:20,863 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 353 seconds and processed:
05 Dec 2020 16:49:20,864 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:49:20,864 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.436 MB text sent to index
05 Dec 2020 16:49:20,864 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:49:21,919 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,100 docs
05 Dec 2020 16:49:23,913 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,200 docs
05 Dec 2020 16:49:25,957 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,300 docs
05 Dec 2020 16:49:28,859 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,400 docs
05 Dec 2020 16:49:30,856 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,500 docs
05 Dec 2020 16:49:31,933 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,600 docs
05 Dec 2020 16:49:33,892 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,700 docs
05 Dec 2020 16:49:35,881 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,800 docs
05 Dec 2020 16:49:37,908 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,900 docs
05 Dec 2020 16:49:39,990 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,000 docs
05 Dec 2020 16:49:39,990 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 18,000, total skipped docs: 0
05 Dec 2020 16:49:39,990 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:49:39,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 372 seconds and processed:
05 Dec 2020 16:49:39,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:49:39,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.696 MB text sent to index
05 Dec 2020 16:49:39,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:49:42,101 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,100 docs
05 Dec 2020 16:49:44,009 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,200 docs
05 Dec 2020 16:49:45,913 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,300 docs
05 Dec 2020 16:49:47,919 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,400 docs
05 Dec 2020 16:49:49,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,500 docs
05 Dec 2020 16:49:51,982 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,600 docs
05 Dec 2020 16:49:53,913 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,700 docs
05 Dec 2020 16:49:55,946 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,800 docs
05 Dec 2020 16:49:58,869 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,900 docs
05 Dec 2020 16:50:00,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,000 docs
05 Dec 2020 16:50:00,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 19,000, total skipped docs: 0
05 Dec 2020 16:50:00,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:50:00,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 393 seconds and processed:
05 Dec 2020 16:50:00,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:50:00,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.957 MB text sent to index
05 Dec 2020 16:50:00,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:50:02,919 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,100 docs
05 Dec 2020 16:50:04,870 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,200 docs
05 Dec 2020 16:50:06,901 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,300 docs
05 Dec 2020 16:50:08,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,400 docs
05 Dec 2020 16:50:10,955 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,500 docs
05 Dec 2020 16:50:12,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,600 docs
05 Dec 2020 16:50:14,984 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,700 docs
05 Dec 2020 16:50:16,962 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,800 docs
05 Dec 2020 16:50:18,990 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,900 docs
05 Dec 2020 16:50:20,946 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,000 docs
05 Dec 2020 16:50:20,947 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 20,000, total skipped docs: 0
05 Dec 2020 16:50:20,947 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:50:20,947 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 413 seconds and processed:
05 Dec 2020 16:50:20,947 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:50:20,947 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     5.216 MB text sent to index
05 Dec 2020 16:50:20,947 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:50:22,936 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,100 docs
05 Dec 2020 16:50:24,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,200 docs
05 Dec 2020 16:50:26,921 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,300 docs
05 Dec 2020 16:50:28,886 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,400 docs
05 Dec 2020 16:50:30,940 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,500 docs
05 Dec 2020 16:50:32,932 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,600 docs
05 Dec 2020 16:50:35,036 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,700 docs
05 Dec 2020 16:50:36,975 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,800 docs
05 Dec 2020 16:50:39,013 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 20,900 docs
05 Dec 2020 16:50:41,892 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,000 docs
05 Dec 2020 16:50:41,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 21,000, total skipped docs: 0
05 Dec 2020 16:50:41,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:50:41,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 434 seconds and processed:
05 Dec 2020 16:50:41,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:50:41,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     5.481 MB text sent to index
05 Dec 2020 16:50:41,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:50:43,974 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,100 docs
05 Dec 2020 16:50:45,940 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,200 docs
05 Dec 2020 16:50:47,944 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,300 docs
05 Dec 2020 16:50:50,858 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,400 docs
05 Dec 2020 16:50:51,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,500 docs
05 Dec 2020 16:50:53,985 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,600 docs
05 Dec 2020 16:50:56,299 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1230789908635230208,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607167251127","id":1269313902220922880}}
05 Dec 2020 16:50:56,930 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,700 docs
05 Dec 2020 16:50:58,955 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,800 docs
05 Dec 2020 16:51:00,954 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 21,900 docs
05 Dec 2020 16:51:02,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,000 docs
05 Dec 2020 16:51:02,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 22,000, total skipped docs: 0
05 Dec 2020 16:51:02,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:51:02,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 455 seconds and processed:
05 Dec 2020 16:51:02,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:51:02,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     5.741 MB text sent to index
05 Dec 2020 16:51:02,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:51:04,951 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,100 docs
05 Dec 2020 16:51:07,098 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,200 docs
05 Dec 2020 16:51:09,068 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,300 docs
05 Dec 2020 16:51:11,099 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,400 docs
05 Dec 2020 16:51:12,143 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":3049271016,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607167266969","id":1252905982126166017}}
05 Dec 2020 16:51:12,937 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,500 docs
05 Dec 2020 16:51:15,033 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,600 docs
05 Dec 2020 16:51:16,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,700 docs
05 Dec 2020 16:51:18,881 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,800 docs
05 Dec 2020 16:51:20,954 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 22,900 docs
05 Dec 2020 16:51:22,859 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,000 docs
05 Dec 2020 16:51:22,859 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 23,000, total skipped docs: 0
05 Dec 2020 16:51:22,860 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:51:22,860 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 475 seconds and processed:
05 Dec 2020 16:51:22,860 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:51:22,860 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     5.998 MB text sent to index
05 Dec 2020 16:51:22,861 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:51:23,937 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,100 docs
05 Dec 2020 16:51:26,865 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,200 docs
05 Dec 2020 16:51:28,922 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,300 docs
05 Dec 2020 16:51:29,951 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,400 docs
05 Dec 2020 16:51:32,104 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,500 docs
05 Dec 2020 16:51:34,181 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,600 docs
05 Dec 2020 16:51:36,049 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,700 docs
05 Dec 2020 16:51:37,885 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,800 docs
05 Dec 2020 16:51:39,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 23,900 docs
05 Dec 2020 16:51:41,951 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,000 docs
05 Dec 2020 16:51:41,951 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 24,000, total skipped docs: 0
05 Dec 2020 16:51:41,951 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:51:41,951 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 494 seconds and processed:
05 Dec 2020 16:51:41,952 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:51:41,952 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     6.252 MB text sent to index
05 Dec 2020 16:51:41,952 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:51:43,931 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,100 docs
05 Dec 2020 16:51:45,955 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,200 docs
05 Dec 2020 16:51:47,907 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,300 docs
05 Dec 2020 16:51:49,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,400 docs
05 Dec 2020 16:51:51,880 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,500 docs
05 Dec 2020 16:51:53,908 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,600 docs
05 Dec 2020 16:51:55,879 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,700 docs
05 Dec 2020 16:51:57,870 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,800 docs
05 Dec 2020 16:51:59,011 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 24,900 docs
05 Dec 2020 16:52:00,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,000 docs
05 Dec 2020 16:52:00,942 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 25,000, total skipped docs: 0
05 Dec 2020 16:52:00,942 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:52:00,942 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 513 seconds and processed:
05 Dec 2020 16:52:00,942 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:52:00,942 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     6.517 MB text sent to index
05 Dec 2020 16:52:00,942 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:52:02,864 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,100 docs
05 Dec 2020 16:52:04,000 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,200 docs
05 Dec 2020 16:52:06,000 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,300 docs
05 Dec 2020 16:52:07,903 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,400 docs
05 Dec 2020 16:52:09,935 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,500 docs
05 Dec 2020 16:52:10,968 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,600 docs
05 Dec 2020 16:52:12,963 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,700 docs
05 Dec 2020 16:52:15,137 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,800 docs
05 Dec 2020 16:52:17,038 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 25,900 docs
05 Dec 2020 16:52:19,013 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,000 docs
05 Dec 2020 16:52:19,013 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 26,000, total skipped docs: 0
05 Dec 2020 16:52:19,014 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     48 docs/second
05 Dec 2020 16:52:19,014 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 531 seconds and processed:
05 Dec 2020 16:52:19,014 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:52:19,014 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     6.766 MB text sent to index
05 Dec 2020 16:52:19,014 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:52:20,949 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,100 docs
05 Dec 2020 16:52:23,032 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,200 docs
05 Dec 2020 16:52:24,966 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,300 docs
05 Dec 2020 16:52:26,867 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,400 docs
05 Dec 2020 16:52:27,918 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,500 docs
05 Dec 2020 16:52:29,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,600 docs
05 Dec 2020 16:52:30,630 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":994367450442543104,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607167345468","id":1229969296496955392}}
05 Dec 2020 16:52:30,994 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,700 docs
05 Dec 2020 16:52:33,198 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,800 docs
05 Dec 2020 16:52:34,971 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 26,900 docs
05 Dec 2020 16:52:36,940 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,000 docs
05 Dec 2020 16:52:36,940 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 27,000, total skipped docs: 0
05 Dec 2020 16:52:36,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     49 docs/second
05 Dec 2020 16:52:36,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 549 seconds and processed:
05 Dec 2020 16:52:36,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:52:36,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     7.019 MB text sent to index
05 Dec 2020 16:52:36,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:52:38,876 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,100 docs
05 Dec 2020 16:52:40,054 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,200 docs
05 Dec 2020 16:52:41,986 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,300 docs
05 Dec 2020 16:52:44,000 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,400 docs
05 Dec 2020 16:52:45,867 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,500 docs
05 Dec 2020 16:52:48,104 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,600 docs
05 Dec 2020 16:52:49,971 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,700 docs
05 Dec 2020 16:52:51,868 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,800 docs
05 Dec 2020 16:52:53,185 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 27,900 docs
05 Dec 2020 16:52:55,112 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 28,000 docs
05 Dec 2020 16:52:55,112 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 28,000, total skipped docs: 0
05 Dec 2020 16:52:55,113 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     49 docs/second
05 Dec 2020 16:52:55,113 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 567 seconds and processed:
05 Dec 2020 16:52:55,113 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 16:52:55,113 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     7.273 MB text sent to index
05 Dec 2020 16:52:55,113 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 16:52:57,048 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 28,100 docs
05 Dec 2020 16:52:59,053 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 28,200 docs
05 Dec 2020 16:53:00,976 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 28,300 docs
05 Dec 2020 16:53:02,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 28,400 docs
05 Dec 2020 16:53:04,860 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 28,500 docs
05 Dec 2020 16:53:06,576 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1220336298927493120,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607167381413","id":1250146910234607619}}
05 Dec 2020 16:53:09,966 ERROR [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
org.apache.flume.ChannelException: Unable to put event on required channel: org.apache.flume.channel.MemoryChannel{name: FileChannel}
	at org.apache.flume.channel.ChannelProcessor.processEvent(ChannelProcessor.java:275)
	at org.apache.flume.source.twitter.TwitterSource.onStatus(TwitterSource.java:173)
	at twitter4j.StatusStreamImpl.onStatus(StatusStreamImpl.java:75)
	at twitter4j.StatusStreamBase$1.run(StatusStreamBase.java:114)
	at twitter4j.internal.async.ExecuteThread.run(DispatcherImpl.java:116)
Caused by: org.apache.flume.ChannelException: Cannot commit transaction. Byte capacity allocated to store event body 1.30862E7reached. Please increase heap space/byte capacity allocated to the channel as the sinks may not be keeping up with the sources
	at org.apache.flume.channel.MemoryChannel$MemoryTransaction.doCommit(MemoryChannel.java:123)
	at org.apache.flume.channel.BasicTransactionSemantics.commit(BasicTransactionSemantics.java:151)
	at org.apache.flume.channel.ChannelProcessor.processEvent(ChannelProcessor.java:267)
	... 4 more
05 Dec 2020 16:59:20,623 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
05 Dec 2020 16:59:20,633 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
05 Dec 2020 16:59:20,633 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 16:59:20,662 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 16:59:20,662 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: FileChannel stopped
05 Dec 2020 16:59:20,719 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.start.time == 1607166807697
05 Dec 2020 16:59:20,720 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.stop.time == 1607167760662
05 Dec 2020 16:59:20,720 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.capacity == 10000
05 Dec 2020 16:59:20,720 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.current.size == 533
05 Dec 2020 16:59:20,720 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.put.attempt == 534
05 Dec 2020 16:59:20,720 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.put.success == 533
05 Dec 2020 16:59:20,720 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.take.attempt == 2
05 Dec 2020 16:59:20,720 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.take.success == 0
05 Dec 2020 16:59:20,720 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.HDFSEventSink.stop:492)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData
05 Dec 2020 16:59:20,721 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing null
05 Dec 2020 16:59:20,755 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.BucketWriter.close:378)  - HDFSWriter is already closed: null
05 Dec 2020 16:59:20,756 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 16:59:20,756 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607166807712
05 Dec 2020 16:59:20,756 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607167760756
05 Dec 2020 16:59:20,756 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 16:59:20,756 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 1
05 Dec 2020 16:59:20,756 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
05 Dec 2020 16:59:20,756 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 16:59:20,756 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
05 Dec 2020 16:59:20,756 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
05 Dec 2020 16:59:20,756 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
05 Dec 2020 16:59:20,757 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 17:01:08,805 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
05 Dec 2020 17:01:08,829 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:/home/tanishka/Downloads/Flume/apache-flume-1.6.0-bin/conf/twitter.conf
05 Dec 2020 17:01:08,875 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:01:08,876 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:01:08,877 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:01:08,877 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:01:08,878 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:01:08,878 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 17:01:08,879 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:01:08,880 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:01:08,880 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:01:08,926 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 17:01:08,927 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 17:01:08,949 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel FileChannel type memory
05 Dec 2020 17:01:08,975 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel FileChannel
05 Dec 2020 17:01:08,977 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 17:01:09,007 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        'qM5WhxIzaHRRvlqbcol7YhB1o'
05 Dec 2020 17:01:09,008 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     'dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie'
05 Dec 2020 17:01:09,008 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        '1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo'
05 Dec 2020 17:01:09,009 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: 'bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz'
05 Dec 2020 17:01:09,422 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 17:01:09,437 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel FileChannel connected to [Twitter, HDFS]
05 Dec 2020 17:01:09,445 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@4336036c counterGroup:{ name:null counters:{} } }} channels:{FileChannel=org.apache.flume.channel.MemoryChannel{name: FileChannel}} }
05 Dec 2020 17:01:09,477 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel FileChannel
05 Dec 2020 17:01:09,881 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: FileChannel: Successfully registered new MBean.
05 Dec 2020 17:01:09,881 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: FileChannel started
05 Dec 2020 17:01:09,882 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 17:01:09,883 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 17:01:09,885 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 17:01:09,891 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 17:01:09,891 INFO  [lifecycleSupervisor-1-1] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 17:01:09,891 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 17:01:09,891 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 17:01:11,855 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Connection established.
05 Dec 2020 17:01:11,865 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Receiving status stream.
05 Dec 2020 17:01:12,114 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.HDFSDataStream.configure:58)  - Serializer = TEXT, UseRawLocalFileSystem = false
05 Dec 2020 17:01:12,478 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.HDFSEventSink.process:459)  - process failed
java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument(ZLjava/lang/String;Ljava/lang/Object;)V
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:1380)
	at org.apache.hadoop.conf.Configuration.set(Configuration.java:1361)
	at org.apache.hadoop.conf.Configuration.setBoolean(Configuration.java:1703)
	at org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:209)
	at org.apache.flume.sink.hdfs.BucketWriter.append(BucketWriter.java:514)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:418)
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:748)
05 Dec 2020 17:01:13,114 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 100 docs
05 Dec 2020 17:01:14,915 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 200 docs
05 Dec 2020 17:01:16,927 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 300 docs
05 Dec 2020 17:01:18,915 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 400 docs
05 Dec 2020 17:01:20,885 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 500 docs
05 Dec 2020 17:01:22,892 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 600 docs
05 Dec 2020 17:01:23,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 700 docs
05 Dec 2020 17:01:25,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 800 docs
05 Dec 2020 17:01:28,874 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 900 docs
05 Dec 2020 17:01:30,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,000 docs
05 Dec 2020 17:01:30,926 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 1,000, total skipped docs: 0
05 Dec 2020 17:01:30,935 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     47 docs/second
05 Dec 2020 17:01:30,936 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 21 seconds and processed:
05 Dec 2020 17:01:30,957 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 17:01:30,957 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.266 MB text sent to index
05 Dec 2020 17:01:30,957 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:01:31,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,100 docs
05 Dec 2020 17:01:33,983 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,200 docs
05 Dec 2020 17:01:35,913 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,300 docs
05 Dec 2020 17:01:37,915 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,400 docs
05 Dec 2020 17:01:40,867 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,500 docs
05 Dec 2020 17:01:42,083 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,600 docs
05 Dec 2020 17:01:44,868 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,700 docs
05 Dec 2020 17:01:45,927 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,800 docs
05 Dec 2020 17:01:47,935 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,900 docs
05 Dec 2020 17:01:49,923 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,000 docs
05 Dec 2020 17:01:49,932 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 2,000, total skipped docs: 0
05 Dec 2020 17:01:49,933 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     50 docs/second
05 Dec 2020 17:01:49,934 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 40 seconds and processed:
05 Dec 2020 17:01:49,935 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 17:01:49,935 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.528 MB text sent to index
05 Dec 2020 17:01:49,936 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:01:51,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,100 docs
05 Dec 2020 17:01:53,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,200 docs
05 Dec 2020 17:01:55,912 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,300 docs
05 Dec 2020 17:01:56,938 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,400 docs
05 Dec 2020 17:01:58,933 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,500 docs
05 Dec 2020 17:02:00,898 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,600 docs
05 Dec 2020 17:02:02,898 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,700 docs
05 Dec 2020 17:02:04,871 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,800 docs
05 Dec 2020 17:02:06,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,900 docs
05 Dec 2020 17:02:08,882 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,000 docs
05 Dec 2020 17:02:08,882 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 3,000, total skipped docs: 0
05 Dec 2020 17:02:08,882 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     51 docs/second
05 Dec 2020 17:02:08,884 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 58 seconds and processed:
05 Dec 2020 17:02:08,884 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.014 MB/sec sent to index
05 Dec 2020 17:02:08,884 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.793 MB text sent to index
05 Dec 2020 17:02:08,885 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:02:10,112 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,100 docs
05 Dec 2020 17:02:11,925 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,200 docs
05 Dec 2020 17:02:14,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,300 docs
05 Dec 2020 17:02:16,834 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,400 docs
05 Dec 2020 17:02:17,982 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,500 docs
05 Dec 2020 17:02:19,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,600 docs
05 Dec 2020 17:02:21,945 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,700 docs
05 Dec 2020 17:02:23,926 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,800 docs
05 Dec 2020 17:02:26,014 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 3,900 docs
05 Dec 2020 17:02:27,937 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,000 docs
05 Dec 2020 17:02:27,937 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 4,000, total skipped docs: 0
05 Dec 2020 17:02:27,939 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     51 docs/second
05 Dec 2020 17:02:27,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 78 seconds and processed:
05 Dec 2020 17:02:27,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.014 MB/sec sent to index
05 Dec 2020 17:02:27,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.055 MB text sent to index
05 Dec 2020 17:02:27,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:02:29,922 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,100 docs
05 Dec 2020 17:02:31,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,200 docs
05 Dec 2020 17:02:34,603 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,300 docs
05 Dec 2020 17:02:37,992 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,400 docs
05 Dec 2020 17:02:55,824 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,500 docs
05 Dec 2020 17:02:56,629 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,600 docs
05 Dec 2020 17:02:57,865 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,700 docs
05 Dec 2020 17:02:58,789 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,800 docs
05 Dec 2020 17:03:00,334 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 4,900 docs
05 Dec 2020 17:03:01,001 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,000 docs
05 Dec 2020 17:03:01,001 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 5,000, total skipped docs: 0
05 Dec 2020 17:03:01,002 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     45 docs/second
05 Dec 2020 17:03:01,002 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 111 seconds and processed:
05 Dec 2020 17:03:01,002 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.012 MB/sec sent to index
05 Dec 2020 17:03:01,002 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.314 MB text sent to index
05 Dec 2020 17:03:01,003 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:03:02,040 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,100 docs
05 Dec 2020 17:03:02,528 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,200 docs
05 Dec 2020 17:03:02,849 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,300 docs
05 Dec 2020 17:03:08,502 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,400 docs
05 Dec 2020 17:03:08,918 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,500 docs
05 Dec 2020 17:03:09,746 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,600 docs
05 Dec 2020 17:03:10,063 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,700 docs
05 Dec 2020 17:03:10,192 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,800 docs
05 Dec 2020 17:03:10,464 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 5,900 docs
05 Dec 2020 17:03:10,627 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,000 docs
05 Dec 2020 17:03:10,628 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 6,000, total skipped docs: 0
05 Dec 2020 17:03:10,628 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     50 docs/second
05 Dec 2020 17:03:10,628 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 120 seconds and processed:
05 Dec 2020 17:03:10,628 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 17:03:10,629 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.571 MB text sent to index
05 Dec 2020 17:03:10,629 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:03:10,812 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,100 docs
05 Dec 2020 17:03:11,086 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,200 docs
05 Dec 2020 17:03:11,480 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,300 docs
05 Dec 2020 17:03:13,019 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,400 docs
05 Dec 2020 17:03:14,881 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,500 docs
05 Dec 2020 17:03:15,930 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,600 docs
05 Dec 2020 17:03:17,918 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,700 docs
05 Dec 2020 17:03:19,938 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,800 docs
05 Dec 2020 17:03:21,102 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 6,900 docs
05 Dec 2020 17:03:23,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,000 docs
05 Dec 2020 17:03:23,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 7,000, total skipped docs: 0
05 Dec 2020 17:03:23,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     52 docs/second
05 Dec 2020 17:03:23,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 134 seconds and processed:
05 Dec 2020 17:03:23,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.014 MB/sec sent to index
05 Dec 2020 17:03:23,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     1.828 MB text sent to index
05 Dec 2020 17:03:23,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:03:25,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,100 docs
05 Dec 2020 17:03:27,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,200 docs
05 Dec 2020 17:03:30,101 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,300 docs
05 Dec 2020 17:03:31,913 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,400 docs
05 Dec 2020 17:03:33,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,500 docs
05 Dec 2020 17:03:35,906 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,600 docs
05 Dec 2020 17:03:37,984 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,700 docs
05 Dec 2020 17:03:39,875 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,800 docs
05 Dec 2020 17:03:41,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 7,900 docs
05 Dec 2020 17:03:42,916 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,000 docs
05 Dec 2020 17:03:42,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 8,000, total skipped docs: 0
05 Dec 2020 17:03:42,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     52 docs/second
05 Dec 2020 17:03:42,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 153 seconds and processed:
05 Dec 2020 17:03:42,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.014 MB/sec sent to index
05 Dec 2020 17:03:42,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.083 MB text sent to index
05 Dec 2020 17:03:42,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:03:44,907 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,100 docs
05 Dec 2020 17:03:46,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,200 docs
05 Dec 2020 17:03:49,536 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,300 docs
05 Dec 2020 17:03:50,898 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,400 docs
05 Dec 2020 17:03:52,872 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,500 docs
05 Dec 2020 17:03:54,883 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,600 docs
05 Dec 2020 17:03:56,875 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,700 docs
05 Dec 2020 17:03:58,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,800 docs
05 Dec 2020 17:04:00,875 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 8,900 docs
05 Dec 2020 17:04:02,910 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,000 docs
05 Dec 2020 17:04:02,910 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 9,000, total skipped docs: 0
05 Dec 2020 17:04:02,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     52 docs/second
05 Dec 2020 17:04:02,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 173 seconds and processed:
05 Dec 2020 17:04:02,911 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.014 MB/sec sent to index
05 Dec 2020 17:04:02,912 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.341 MB text sent to index
05 Dec 2020 17:04:02,912 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:04:03,304 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1104485600046899201,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607168038135","id":1259141230233038850}}
05 Dec 2020 17:04:04,903 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,100 docs
05 Dec 2020 17:04:05,954 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,200 docs
05 Dec 2020 17:04:07,914 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,300 docs
05 Dec 2020 17:04:09,914 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,400 docs
05 Dec 2020 17:04:12,158 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,500 docs
05 Dec 2020 17:04:13,976 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,600 docs
05 Dec 2020 17:04:15,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,700 docs
05 Dec 2020 17:04:17,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,800 docs
05 Dec 2020 17:04:20,032 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 9,900 docs
05 Dec 2020 17:04:21,879 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,000 docs
05 Dec 2020 17:04:21,886 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 10,000, total skipped docs: 0
05 Dec 2020 17:04:21,886 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     52 docs/second
05 Dec 2020 17:04:21,886 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 191 seconds and processed:
05 Dec 2020 17:04:21,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.014 MB/sec sent to index
05 Dec 2020 17:04:21,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.6 MB text sent to index
05 Dec 2020 17:04:21,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:04:24,115 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,100 docs
05 Dec 2020 17:04:25,907 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,200 docs
05 Dec 2020 17:04:27,912 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,300 docs
05 Dec 2020 17:04:29,876 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,400 docs
05 Dec 2020 17:04:32,034 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,500 docs
05 Dec 2020 17:04:35,383 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,600 docs
05 Dec 2020 17:04:37,345 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,700 docs
05 Dec 2020 17:04:37,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,800 docs
05 Dec 2020 17:04:39,204 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 10,900 docs
05 Dec 2020 17:04:41,876 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,000 docs
05 Dec 2020 17:04:41,876 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 11,000, total skipped docs: 0
05 Dec 2020 17:04:41,876 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     52 docs/second
05 Dec 2020 17:04:41,876 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 211 seconds and processed:
05 Dec 2020 17:04:41,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.014 MB/sec sent to index
05 Dec 2020 17:04:41,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     2.86 MB text sent to index
05 Dec 2020 17:04:41,877 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:04:42,905 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,100 docs
05 Dec 2020 17:04:44,882 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,200 docs
05 Dec 2020 17:04:46,882 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,300 docs
05 Dec 2020 17:04:48,876 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,400 docs
05 Dec 2020 17:04:49,950 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,500 docs
05 Dec 2020 17:04:53,408 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,600 docs
05 Dec 2020 17:04:54,868 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,700 docs
05 Dec 2020 17:04:58,718 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,800 docs
05 Dec 2020 17:04:59,095 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 11,900 docs
05 Dec 2020 17:05:00,041 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,000 docs
05 Dec 2020 17:05:00,041 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 12,000, total skipped docs: 0
05 Dec 2020 17:05:00,041 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     52 docs/second
05 Dec 2020 17:05:00,041 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 230 seconds and processed:
05 Dec 2020 17:05:00,041 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.014 MB/sec sent to index
05 Dec 2020 17:05:00,041 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.121 MB text sent to index
05 Dec 2020 17:05:00,042 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:05:02,146 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,100 docs
05 Dec 2020 17:05:04,811 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,200 docs
05 Dec 2020 17:05:07,085 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,300 docs
05 Dec 2020 17:05:47,509 INFO  [Twitter Stream consumer-1[Receiving stream]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Stream closed.
05 Dec 2020 17:05:47,509 ERROR [Twitter Stream consumer-1[Receiving stream]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
Stream closed.
Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=a8fd061d or
	http://www.google.co.jp/search?q=00070a0c
TwitterException{exceptionCode=[a8fd061d-00070a0c a8fd061d-0007099a a8fd061d-0007099a], statusCode=-1, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.StatusStreamBase.handleNextElement(StatusStreamBase.java:199)
	at twitter4j.StatusStreamImpl.next(StatusStreamImpl.java:57)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:478)
Caused by: javax.net.ssl.SSLException: Read timed out
	at sun.security.ssl.Alert.createSSLException(Alert.java:127)
	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324)
	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267)
	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262)
	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:135)
	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1146)
	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1116)
	at sun.security.ssl.SSLSocketImpl.access$200(SSLSocketImpl.java:72)
	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:815)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.net.www.http.ChunkedInputStream.readAheadBlocking(ChunkedInputStream.java:552)
	at sun.net.www.http.ChunkedInputStream.readAhead(ChunkedInputStream.java:609)
	at sun.net.www.http.ChunkedInputStream.read(ChunkedInputStream.java:696)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3454)
	at java.util.zip.InflaterInputStream.fill(InflaterInputStream.java:238)
	at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:158)
	at java.util.zip.GZIPInputStream.read(GZIPInputStream.java:117)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at twitter4j.StatusStreamBase.handleNextElement(StatusStreamBase.java:85)
	... 2 more
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:457)
	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:237)
	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190)
	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:108)
	... 25 more
05 Dec 2020 17:05:47,512 INFO  [Twitter Stream consumer-1[Receiving stream]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Stream closed.
05 Dec 2020 17:05:47,512 ERROR [Twitter Stream consumer-1[Receiving stream]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
Stream closed.
Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=a8fd061d or
	http://www.google.co.jp/search?q=00070a0c
TwitterException{exceptionCode=[a8fd061d-00070a0c a8fd061d-0007099a a8fd061d-0007099a], statusCode=-1, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.StatusStreamBase.handleNextElement(StatusStreamBase.java:199)
	at twitter4j.StatusStreamImpl.next(StatusStreamImpl.java:57)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:478)
Caused by: javax.net.ssl.SSLException: Read timed out
	at sun.security.ssl.Alert.createSSLException(Alert.java:127)
	at sun.security.ssl.TransportContext.fatal(TransportContext.java:324)
	at sun.security.ssl.TransportContext.fatal(TransportContext.java:267)
	at sun.security.ssl.TransportContext.fatal(TransportContext.java:262)
	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:135)
	at sun.security.ssl.SSLSocketImpl.decode(SSLSocketImpl.java:1146)
	at sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1116)
	at sun.security.ssl.SSLSocketImpl.access$200(SSLSocketImpl.java:72)
	at sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:815)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:345)
	at sun.net.www.http.ChunkedInputStream.readAheadBlocking(ChunkedInputStream.java:552)
	at sun.net.www.http.ChunkedInputStream.readAhead(ChunkedInputStream.java:609)
	at sun.net.www.http.ChunkedInputStream.read(ChunkedInputStream.java:696)
	at java.io.FilterInputStream.read(FilterInputStream.java:133)
	at sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(HttpURLConnection.java:3454)
	at java.util.zip.InflaterInputStream.fill(InflaterInputStream.java:238)
	at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:158)
	at java.util.zip.GZIPInputStream.read(GZIPInputStream.java:117)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at twitter4j.StatusStreamBase.handleNextElement(StatusStreamBase.java:85)
	... 2 more
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.net.SocketInputStream.socketRead0(Native Method)
	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116)
	at java.net.SocketInputStream.read(SocketInputStream.java:171)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:457)
	at sun.security.ssl.SSLSocketInputRecord.decodeInputRecord(SSLSocketInputRecord.java:237)
	at sun.security.ssl.SSLSocketInputRecord.decode(SSLSocketInputRecord.java:190)
	at sun.security.ssl.SSLTransport.decode(SSLTransport.java:108)
	... 25 more
05 Dec 2020 17:05:47,513 INFO  [Twitter Stream consumer-1[Receiving stream]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 250 milliseconds
05 Dec 2020 17:05:47,763 INFO  [Twitter Stream consumer-1[Waiting for 250 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 17:05:57,785 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - stream.twitter.com
05 Dec 2020 17:05:57,786 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
stream.twitter.com
Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75522
TwitterException{exceptionCode=[d0031b0b-1db75522 db667dea-99334ae4], statusCode=-1, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:192)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
Caused by: java.net.UnknownHostException: stream.twitter.com
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:284)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558)
	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264)
	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1162)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1056)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1570)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:352)
	at twitter4j.internal.http.HttpResponseImpl.<init>(HttpResponseImpl.java:34)
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:156)
	... 5 more
05 Dec 2020 17:05:57,789 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 500 milliseconds
05 Dec 2020 17:05:58,290 INFO  [Twitter Stream consumer-1[Waiting for 500 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 17:05:58,303 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - stream.twitter.com
05 Dec 2020 17:05:58,304 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
stream.twitter.com
Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75522
TwitterException{exceptionCode=[d0031b0b-1db75522 db667dea-99334ae4], statusCode=-1, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:192)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
Caused by: java.net.UnknownHostException: stream.twitter.com
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:284)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558)
	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264)
	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1162)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1056)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1570)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:352)
	at twitter4j.internal.http.HttpResponseImpl.<init>(HttpResponseImpl.java:34)
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:156)
	... 5 more
05 Dec 2020 17:05:58,305 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 1000 milliseconds
05 Dec 2020 17:05:59,307 INFO  [Twitter Stream consumer-1[Waiting for 1000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 17:05:59,310 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - stream.twitter.com
05 Dec 2020 17:05:59,310 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
stream.twitter.com
Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75522
TwitterException{exceptionCode=[d0031b0b-1db75522 db667dea-99334ae4], statusCode=-1, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:192)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
Caused by: java.net.UnknownHostException: stream.twitter.com
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:284)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558)
	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264)
	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1162)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1056)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1570)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:352)
	at twitter4j.internal.http.HttpResponseImpl.<init>(HttpResponseImpl.java:34)
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:156)
	... 5 more
05 Dec 2020 17:05:59,310 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 2000 milliseconds
05 Dec 2020 17:06:01,311 INFO  [Twitter Stream consumer-1[Waiting for 2000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 17:06:01,827 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - stream.twitter.com
05 Dec 2020 17:06:01,827 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
stream.twitter.com
Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75522
TwitterException{exceptionCode=[d0031b0b-1db75522 db667dea-99334ae4], statusCode=-1, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:192)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
Caused by: java.net.UnknownHostException: stream.twitter.com
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:284)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558)
	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264)
	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1162)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1056)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1570)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:352)
	at twitter4j.internal.http.HttpResponseImpl.<init>(HttpResponseImpl.java:34)
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:156)
	... 5 more
05 Dec 2020 17:06:01,828 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 4000 milliseconds
05 Dec 2020 17:06:05,829 INFO  [Twitter Stream consumer-1[Waiting for 4000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 17:06:05,831 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - stream.twitter.com
05 Dec 2020 17:06:05,831 ERROR [Twitter Stream consumer-1[Establishing connection]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
stream.twitter.com
Relevant discussions can be found on the Internet at:
	http://www.google.co.jp/search?q=d0031b0b or
	http://www.google.co.jp/search?q=1db75522
TwitterException{exceptionCode=[d0031b0b-1db75522 db667dea-99334ae4], statusCode=-1, message=null, code=-1, retryAfter=-1, rateLimitStatus=null, version=3.0.3}
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:192)
	at twitter4j.internal.http.HttpClientWrapper.request(HttpClientWrapper.java:61)
	at twitter4j.internal.http.HttpClientWrapper.get(HttpClientWrapper.java:89)
	at twitter4j.TwitterStreamImpl.getSampleStream(TwitterStreamImpl.java:176)
	at twitter4j.TwitterStreamImpl$4.getStream(TwitterStreamImpl.java:164)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:462)
Caused by: java.net.UnknownHostException: stream.twitter.com
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:184)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:607)
	at sun.security.ssl.SSLSocketImpl.connect(SSLSocketImpl.java:284)
	at sun.net.NetworkClient.doConnect(NetworkClient.java:175)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:463)
	at sun.net.www.http.HttpClient.openServer(HttpClient.java:558)
	at sun.net.www.protocol.https.HttpsClient.<init>(HttpsClient.java:264)
	at sun.net.www.protocol.https.HttpsClient.New(HttpsClient.java:367)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.getNewHttpClient(AbstractDelegateHttpsURLConnection.java:191)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect0(HttpURLConnection.java:1162)
	at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:1056)
	at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:177)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1570)
	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1498)
	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480)
	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:352)
	at twitter4j.internal.http.HttpResponseImpl.<init>(HttpResponseImpl.java:34)
	at twitter4j.internal.http.HttpClientImpl.request(HttpClientImpl.java:156)
	... 5 more
05 Dec 2020 17:06:05,832 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Waiting for 8000 milliseconds
05 Dec 2020 17:06:13,832 INFO  [Twitter Stream consumer-1[Waiting for 8000 milliseconds]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 17:06:15,878 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Connection established.
05 Dec 2020 17:06:15,879 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Receiving status stream.
05 Dec 2020 17:06:16,901 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,400 docs
05 Dec 2020 17:06:18,881 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,500 docs
05 Dec 2020 17:06:20,885 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,600 docs
05 Dec 2020 17:06:21,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,700 docs
05 Dec 2020 17:06:23,964 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,800 docs
05 Dec 2020 17:06:25,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 12,900 docs
05 Dec 2020 17:06:27,895 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,000 docs
05 Dec 2020 17:06:27,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 13,000, total skipped docs: 0
05 Dec 2020 17:06:27,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     40 docs/second
05 Dec 2020 17:06:27,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 318 seconds and processed:
05 Dec 2020 17:06:27,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.011 MB/sec sent to index
05 Dec 2020 17:06:27,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.379 MB text sent to index
05 Dec 2020 17:06:27,897 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:06:29,884 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,100 docs
05 Dec 2020 17:06:30,915 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,200 docs
05 Dec 2020 17:06:32,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,300 docs
05 Dec 2020 17:06:34,922 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,400 docs
05 Dec 2020 17:06:36,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,500 docs
05 Dec 2020 17:06:38,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,600 docs
05 Dec 2020 17:06:40,889 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,700 docs
05 Dec 2020 17:06:42,883 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,800 docs
05 Dec 2020 17:06:43,917 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 13,900 docs
05 Dec 2020 17:06:45,926 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,000 docs
05 Dec 2020 17:06:45,926 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 14,000, total skipped docs: 0
05 Dec 2020 17:06:45,926 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     41 docs/second
05 Dec 2020 17:06:45,927 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 336 seconds and processed:
05 Dec 2020 17:06:45,927 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.011 MB/sec sent to index
05 Dec 2020 17:06:45,927 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.638 MB text sent to index
05 Dec 2020 17:06:45,932 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:06:47,940 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,100 docs
05 Dec 2020 17:06:49,895 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,200 docs
05 Dec 2020 17:06:51,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,300 docs
05 Dec 2020 17:06:52,916 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,400 docs
05 Dec 2020 17:06:54,904 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,500 docs
05 Dec 2020 17:06:56,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,600 docs
05 Dec 2020 17:06:58,884 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,700 docs
05 Dec 2020 17:06:59,936 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,800 docs
05 Dec 2020 17:07:01,892 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 14,900 docs
05 Dec 2020 17:07:03,898 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,000 docs
05 Dec 2020 17:07:03,899 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 15,000, total skipped docs: 0
05 Dec 2020 17:07:03,899 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     42 docs/second
05 Dec 2020 17:07:03,899 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 354 seconds and processed:
05 Dec 2020 17:07:03,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.011 MB/sec sent to index
05 Dec 2020 17:07:03,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     3.902 MB text sent to index
05 Dec 2020 17:07:03,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:07:05,899 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,100 docs
05 Dec 2020 17:07:07,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,200 docs
05 Dec 2020 17:07:09,916 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,300 docs
05 Dec 2020 17:07:11,932 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,400 docs
05 Dec 2020 17:07:13,864 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,500 docs
05 Dec 2020 17:07:14,926 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,600 docs
05 Dec 2020 17:07:16,968 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,700 docs
05 Dec 2020 17:07:18,896 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,800 docs
05 Dec 2020 17:07:19,038 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":836922866646020096,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607168233815","id":1289347793950105601}}
05 Dec 2020 17:07:20,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 15,900 docs
05 Dec 2020 17:07:22,892 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,000 docs
05 Dec 2020 17:07:22,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 16,000, total skipped docs: 0
05 Dec 2020 17:07:22,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     42 docs/second
05 Dec 2020 17:07:22,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 373 seconds and processed:
05 Dec 2020 17:07:22,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.011 MB/sec sent to index
05 Dec 2020 17:07:22,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.161 MB text sent to index
05 Dec 2020 17:07:22,893 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:07:24,874 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,100 docs
05 Dec 2020 17:07:25,922 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,200 docs
05 Dec 2020 17:07:27,898 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,300 docs
05 Dec 2020 17:07:29,919 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,400 docs
05 Dec 2020 17:07:32,021 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,500 docs
05 Dec 2020 17:07:33,908 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,600 docs
05 Dec 2020 17:07:35,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,700 docs
05 Dec 2020 17:07:37,352 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,800 docs
05 Dec 2020 17:07:38,916 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 16,900 docs
05 Dec 2020 17:07:40,937 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,000 docs
05 Dec 2020 17:07:40,937 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 17,000, total skipped docs: 0
05 Dec 2020 17:07:40,938 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     43 docs/second
05 Dec 2020 17:07:40,938 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 391 seconds and processed:
05 Dec 2020 17:07:40,938 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.011 MB/sec sent to index
05 Dec 2020 17:07:40,939 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.422 MB text sent to index
05 Dec 2020 17:07:40,939 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:07:42,901 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,100 docs
05 Dec 2020 17:07:44,909 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,200 docs
05 Dec 2020 17:07:46,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,300 docs
05 Dec 2020 17:07:48,883 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,400 docs
05 Dec 2020 17:07:49,912 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,500 docs
05 Dec 2020 17:07:51,992 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,600 docs
05 Dec 2020 17:07:53,397 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":2206482719,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607168268202","id":1290079456737075200}}
05 Dec 2020 17:07:53,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,700 docs
05 Dec 2020 17:07:55,884 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,800 docs
05 Dec 2020 17:07:56,018 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":789655995358130176,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607168270843","id":1186661471914209280}}
05 Dec 2020 17:07:56,996 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 17,900 docs
05 Dec 2020 17:07:59,886 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,000 docs
05 Dec 2020 17:07:59,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 18,000, total skipped docs: 0
05 Dec 2020 17:07:59,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     43 docs/second
05 Dec 2020 17:07:59,887 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 410 seconds and processed:
05 Dec 2020 17:07:59,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.011 MB/sec sent to index
05 Dec 2020 17:07:59,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.688 MB text sent to index
05 Dec 2020 17:07:59,888 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:08:00,892 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,100 docs
05 Dec 2020 17:08:01,266 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":3029917937,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607168276087","id":1244835713394212865}}
05 Dec 2020 17:08:02,880 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,200 docs
05 Dec 2020 17:08:03,994 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,300 docs
05 Dec 2020 17:08:06,004 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,400 docs
05 Dec 2020 17:08:07,885 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,500 docs
05 Dec 2020 17:08:09,873 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,600 docs
05 Dec 2020 17:08:10,973 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,700 docs
05 Dec 2020 17:08:12,944 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,800 docs
05 Dec 2020 17:08:14,991 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 18,900 docs
05 Dec 2020 17:08:17,018 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,000 docs
05 Dec 2020 17:08:17,019 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 19,000, total skipped docs: 0
05 Dec 2020 17:08:17,019 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     44 docs/second
05 Dec 2020 17:08:17,020 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 427 seconds and processed:
05 Dec 2020 17:08:17,020 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.012 MB/sec sent to index
05 Dec 2020 17:08:17,020 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     4.949 MB text sent to index
05 Dec 2020 17:08:17,020 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:08:18,940 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,100 docs
05 Dec 2020 17:08:21,010 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,200 docs
05 Dec 2020 17:08:22,974 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,300 docs
05 Dec 2020 17:08:25,009 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,400 docs
05 Dec 2020 17:08:26,894 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 19,500 docs
05 Dec 2020 17:08:27,797 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
05 Dec 2020 17:08:27,805 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
05 Dec 2020 17:08:27,807 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 17:08:27,874 INFO  [Twitter Stream consumer-1[Disposing thread]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Inflater has been closed
05 Dec 2020 17:08:27,874 ERROR [Twitter Stream consumer-1[Disposing thread]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
java.lang.NullPointerException: Inflater has been closed
	at java.util.zip.Inflater.ensureOpen(Inflater.java:389)
	at java.util.zip.Inflater.inflate(Inflater.java:257)
	at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:152)
	at java.util.zip.GZIPInputStream.read(GZIPInputStream.java:117)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at twitter4j.StatusStreamBase.handleNextElement(StatusStreamBase.java:85)
	at twitter4j.StatusStreamImpl.next(StatusStreamImpl.java:57)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:478)
05 Dec 2020 17:08:27,880 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 17:08:27,880 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: FileChannel stopped
05 Dec 2020 17:08:27,880 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.start.time == 1607167869881
05 Dec 2020 17:08:27,880 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.stop.time == 1607168307880
05 Dec 2020 17:08:27,880 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.capacity == 10000
05 Dec 2020 17:08:27,880 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.current.size == 320
05 Dec 2020 17:08:27,880 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.put.attempt == 320
05 Dec 2020 17:08:27,881 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.put.success == 320
05 Dec 2020 17:08:27,881 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.take.attempt == 1
05 Dec 2020 17:08:27,881 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.take.success == 0
05 Dec 2020 17:08:27,881 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.HDFSEventSink.stop:492)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData
05 Dec 2020 17:08:27,888 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing null
05 Dec 2020 17:08:27,890 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.BucketWriter.close:378)  - HDFSWriter is already closed: null
05 Dec 2020 17:08:27,890 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 17:08:27,890 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607167869891
05 Dec 2020 17:08:27,890 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607168307890
05 Dec 2020 17:08:27,890 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 17:08:27,890 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 0
05 Dec 2020 17:08:27,891 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 0
05 Dec 2020 17:08:27,891 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 17:08:27,891 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 0
05 Dec 2020 17:08:27,891 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 0
05 Dec 2020 17:08:27,891 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 0
05 Dec 2020 17:08:27,891 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 17:08:40,640 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.start:61)  - Configuration provider starting
05 Dec 2020 17:08:40,659 INFO  [conf-file-poller-0] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider$FileWatcherRunnable.run:133)  - Reloading configuration file:/home/tanishka/Downloads/Flume/apache-flume-1.6.0-bin/conf/twitter.conf
05 Dec 2020 17:08:40,683 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:08:40,684 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:08:40,685 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:08:40,685 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:08:40,686 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:08:40,687 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:931)  - Added sinks: HDFS Agent: TwitterAgent
05 Dec 2020 17:08:40,688 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:08:40,689 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:08:40,692 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration$AgentConfiguration.addProperty:1017)  - Processing:HDFS
05 Dec 2020 17:08:40,749 INFO  [conf-file-poller-0] (org.apache.flume.conf.FlumeConfiguration.validateConfiguration:141)  - Post-validation flume configuration contains configuration for agents: [TwitterAgent]
05 Dec 2020 17:08:40,750 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:145)  - Creating channels
05 Dec 2020 17:08:40,777 INFO  [conf-file-poller-0] (org.apache.flume.channel.DefaultChannelFactory.create:42)  - Creating instance of channel FileChannel type memory
05 Dec 2020 17:08:40,792 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.loadChannels:200)  - Created channel FileChannel
05 Dec 2020 17:08:40,857 INFO  [conf-file-poller-0] (org.apache.flume.source.DefaultSourceFactory.create:41)  - Creating instance of source Twitter, type org.apache.flume.source.twitter.TwitterSource
05 Dec 2020 17:08:40,900 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:110)  - Consumer Key:        'qM5WhxIzaHRRvlqbcol7YhB1o'
05 Dec 2020 17:08:40,900 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:111)  - Consumer Secret:     'dkTCBkwBBaneRtMlfdiZ2GaqrlSH17IKIOchJ0DiPQAeAW1Zie'
05 Dec 2020 17:08:40,901 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:112)  - Access Token:        '1064935789950320641-pGfdg0EWW4jMuvjkXbENQr8RpG6goo'
05 Dec 2020 17:08:40,901 INFO  [conf-file-poller-0] (org.apache.flume.source.twitter.TwitterSource.configure:113)  - Access Token Secret: 'bxw8G06j1B8EBP7kHn23ayElbpShaCi7YeeaP0WrN7xJz'
05 Dec 2020 17:08:41,647 INFO  [conf-file-poller-0] (org.apache.flume.sink.DefaultSinkFactory.create:42)  - Creating instance of sink: HDFS, type: hdfs
05 Dec 2020 17:08:41,710 INFO  [conf-file-poller-0] (org.apache.flume.node.AbstractConfigurationProvider.getConfiguration:114)  - Channel FileChannel connected to [Twitter, HDFS]
05 Dec 2020 17:08:41,730 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:138)  - Starting new configuration:{ sourceRunners:{Twitter=EventDrivenSourceRunner: { source:org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} }} sinkRunners:{HDFS=SinkRunner: { policy:org.apache.flume.sink.DefaultSinkProcessor@24de2b61 counterGroup:{ name:null counters:{} } }} channels:{FileChannel=org.apache.flume.channel.MemoryChannel{name: FileChannel}} }
05 Dec 2020 17:08:41,737 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:145)  - Starting Channel FileChannel
05 Dec 2020 17:08:42,190 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: CHANNEL, name: FileChannel: Successfully registered new MBean.
05 Dec 2020 17:08:42,190 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: CHANNEL, name: FileChannel started
05 Dec 2020 17:08:42,191 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:173)  - Starting Sink HDFS
05 Dec 2020 17:08:42,195 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.register:120)  - Monitored counter group for type: SINK, name: HDFS: Successfully registered new MBean.
05 Dec 2020 17:08:42,195 INFO  [lifecycleSupervisor-1-0] (org.apache.flume.instrumentation.MonitoredCounterGroup.start:96)  - Component type: SINK, name: HDFS started
05 Dec 2020 17:08:42,195 INFO  [conf-file-poller-0] (org.apache.flume.node.Application.startAllComponents:184)  - Starting Source Twitter
05 Dec 2020 17:08:42,199 INFO  [lifecycleSupervisor-1-2] (org.apache.flume.source.twitter.TwitterSource.start:131)  - Starting twitter source org.apache.flume.source.twitter.TwitterSource{name:Twitter,state:IDLE} ...
05 Dec 2020 17:08:42,207 INFO  [lifecycleSupervisor-1-2] (org.apache.flume.source.twitter.TwitterSource.start:139)  - Twitter source Twitter started.
05 Dec 2020 17:08:42,207 INFO  [Twitter Stream consumer-1[initializing]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Establishing connection.
05 Dec 2020 17:08:45,887 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Connection established.
05 Dec 2020 17:08:45,888 INFO  [Twitter Stream consumer-1[Establishing connection]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Receiving status stream.
05 Dec 2020 17:08:46,287 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.HDFSDataStream.configure:58)  - Serializer = TEXT, UseRawLocalFileSystem = false
05 Dec 2020 17:08:46,944 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326288.tmp
05 Dec 2020 17:08:47,227 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 100 docs
05 Dec 2020 17:08:48,429 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1125452093916164097,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607168323209","id":1267626894427598851}}
05 Dec 2020 17:08:48,976 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 200 docs
05 Dec 2020 17:08:50,910 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 300 docs
05 Dec 2020 17:08:52,938 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 400 docs
05 Dec 2020 17:08:54,037 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 500 docs
05 Dec 2020 17:08:55,945 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 600 docs
05 Dec 2020 17:08:56,974 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.HDFSEventSink.process:455)  - HDFS IO error
java.io.IOException: Callable timed out after 10000 ms on file: hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326288.tmp
	at org.apache.flume.sink.hdfs.BucketWriter.callWithTimeout(BucketWriter.java:693)
	at org.apache.flume.sink.hdfs.BucketWriter.open(BucketWriter.java:235)
	at org.apache.flume.sink.hdfs.BucketWriter.append(BucketWriter.java:514)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:418)
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.util.concurrent.TimeoutException
	at java.util.concurrent.FutureTask.get(FutureTask.java:205)
	at org.apache.flume.sink.hdfs.BucketWriter.callWithTimeout(BucketWriter.java:686)
	... 6 more
05 Dec 2020 17:08:57,890 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 700 docs
05 Dec 2020 17:08:58,977 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 800 docs
05 Dec 2020 17:08:59,155 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326289.tmp
05 Dec 2020 17:09:00,410 WARN  [Thread-11] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326289.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:00,423 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326289.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:00,425 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:00,425 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326289.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:00,427 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326289.tmp
05 Dec 2020 17:09:00,429 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:00,430 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326289.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326289.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:00,477 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326289.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326289
05 Dec 2020 17:09:00,618 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326290.tmp
05 Dec 2020 17:09:00,715 WARN  [Thread-13] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326290.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:00,721 WARN  [hdfs-HDFS-call-runner-8] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326290.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:00,738 ERROR [hdfs-HDFS-call-runner-8] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:00,739 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326290.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:00,741 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326290.tmp
05 Dec 2020 17:09:00,743 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:00,746 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326290.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326290.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:00,752 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326290.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326290
05 Dec 2020 17:09:00,817 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326291.tmp
05 Dec 2020 17:09:01,101 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 900 docs
05 Dec 2020 17:09:01,163 WARN  [Thread-14] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326291.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,182 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326291.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,183 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,184 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326291.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,185 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326291.tmp
05 Dec 2020 17:09:01,188 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,190 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326291.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326291.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,195 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326291.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326291
05 Dec 2020 17:09:01,241 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326292.tmp
05 Dec 2020 17:09:01,289 WARN  [Thread-15] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326292.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,290 WARN  [hdfs-HDFS-call-runner-8] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326292.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,291 ERROR [hdfs-HDFS-call-runner-8] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,292 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326292.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,292 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326292.tmp
05 Dec 2020 17:09:01,293 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,293 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326292.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326292.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,296 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326292.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326292
05 Dec 2020 17:09:01,311 WARN  [Twitter4J Async Dispatcher[0]] (twitter4j.internal.logging.SLF4JLogger.warn:107)  - Received unknown event:{"status_withheld":{"user_id":1010985731068710913,"withheld_in_countries":["xy","xy"],"timestamp_ms":"1607168336116","id":1272103428974694400}}
05 Dec 2020 17:09:01,347 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326293.tmp
05 Dec 2020 17:09:01,465 WARN  [Thread-16] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326293.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,468 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326293.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,469 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,469 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326293.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,470 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326293.tmp
05 Dec 2020 17:09:01,470 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,470 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326293.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326293.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,477 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326293.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326293
05 Dec 2020 17:09:01,504 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326294.tmp
05 Dec 2020 17:09:01,563 WARN  [Thread-17] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326294.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,564 WARN  [hdfs-HDFS-call-runner-8] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326294.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,564 ERROR [hdfs-HDFS-call-runner-8] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,564 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326294.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,565 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326294.tmp
05 Dec 2020 17:09:01,565 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,565 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326294.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326294.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,570 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326294.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326294
05 Dec 2020 17:09:01,600 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326295.tmp
05 Dec 2020 17:09:01,644 WARN  [Thread-18] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326295.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,645 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326295.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,645 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,645 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326295.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,646 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326295.tmp
05 Dec 2020 17:09:01,646 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,646 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326295.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326295.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,660 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326295.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326295
05 Dec 2020 17:09:01,700 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326296.tmp
05 Dec 2020 17:09:01,760 WARN  [Thread-19] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326296.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,762 WARN  [hdfs-HDFS-call-runner-8] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326296.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,763 ERROR [hdfs-HDFS-call-runner-8] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,764 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326296.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,765 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326296.tmp
05 Dec 2020 17:09:01,766 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,768 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326296.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326296.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,784 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326296.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326296
05 Dec 2020 17:09:01,834 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326297.tmp
05 Dec 2020 17:09:01,892 WARN  [Thread-20] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326297.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,908 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326297.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,910 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,930 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326297.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,931 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326297.tmp
05 Dec 2020 17:09:01,933 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:01,945 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326297.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326297.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:01,949 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326297.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326297
05 Dec 2020 17:09:02,023 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326298.tmp
05 Dec 2020 17:09:02,087 WARN  [Thread-21] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326298.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,093 WARN  [hdfs-HDFS-call-runner-8] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326298.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,101 ERROR [hdfs-HDFS-call-runner-8] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,101 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326298.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,102 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326298.tmp
05 Dec 2020 17:09:02,103 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,103 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326298.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326298.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,112 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326298.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326298
05 Dec 2020 17:09:02,164 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326299.tmp
05 Dec 2020 17:09:02,234 WARN  [Thread-22] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326299.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,235 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326299.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,236 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,236 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326299.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,237 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326299.tmp
05 Dec 2020 17:09:02,237 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,238 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326299.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326299.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,244 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326299.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326299
05 Dec 2020 17:09:02,291 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326300.tmp
05 Dec 2020 17:09:02,339 WARN  [Thread-23] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326300.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,341 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326300.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,342 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,343 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326300.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,343 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326300.tmp
05 Dec 2020 17:09:02,343 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,343 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326300.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326300.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,347 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326300.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326300
05 Dec 2020 17:09:02,405 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326301.tmp
05 Dec 2020 17:09:02,479 WARN  [Thread-24] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326301.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,486 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326301.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,486 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,487 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326301.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,488 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326301.tmp
05 Dec 2020 17:09:02,488 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,488 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326301.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326301.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,507 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326301.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326301
05 Dec 2020 17:09:02,552 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326302.tmp
05 Dec 2020 17:09:02,620 WARN  [Thread-25] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326302.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,623 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326302.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,624 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,625 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326302.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,625 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326302.tmp
05 Dec 2020 17:09:02,626 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,627 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326302.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326302.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,639 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326302.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326302
05 Dec 2020 17:09:02,699 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326303.tmp
05 Dec 2020 17:09:02,841 WARN  [Thread-26] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326303.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,848 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326303.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,849 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,852 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326303.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,853 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326303.tmp
05 Dec 2020 17:09:02,854 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:02,855 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326303.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326303.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:02,869 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326303.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326303
05 Dec 2020 17:09:02,916 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,000 docs
05 Dec 2020 17:09:02,935 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 1,000, total skipped docs: 0
05 Dec 2020 17:09:02,936 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     50 docs/second
05 Dec 2020 17:09:02,936 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 20 seconds and processed:
05 Dec 2020 17:09:02,959 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.013 MB/sec sent to index
05 Dec 2020 17:09:02,961 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.265 MB text sent to index
05 Dec 2020 17:09:02,961 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:09:02,982 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326304.tmp
05 Dec 2020 17:09:03,896 WARN  [Thread-27] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326304.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:03,904 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326304.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:03,904 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:03,905 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326304.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:03,905 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326304.tmp
05 Dec 2020 17:09:03,906 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:03,908 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326304.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326304.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:03,914 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326304.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326304
05 Dec 2020 17:09:04,100 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326305.tmp
05 Dec 2020 17:09:04,899 WARN  [Thread-28] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326305.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:04,900 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326305.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:04,901 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:04,926 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326305.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:04,926 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326305.tmp
05 Dec 2020 17:09:04,926 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:04,926 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326305.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326305.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:04,937 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,100 docs
05 Dec 2020 17:09:04,965 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326305.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326305
05 Dec 2020 17:09:05,006 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326306.tmp
05 Dec 2020 17:09:05,943 WARN  [Thread-29] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326306.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:05,946 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326306.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:05,947 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:05,948 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326306.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:05,948 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326306.tmp
05 Dec 2020 17:09:05,949 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:05,953 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326306.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326306.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:05,979 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326306.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326306
05 Dec 2020 17:09:06,041 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326307.tmp
05 Dec 2020 17:09:06,910 WARN  [Thread-30] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326307.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:06,919 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326307.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:06,920 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:06,920 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326307.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:06,921 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326307.tmp
05 Dec 2020 17:09:06,921 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:06,921 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326307.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326307.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:06,926 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326307.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326307
05 Dec 2020 17:09:06,935 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,200 docs
05 Dec 2020 17:09:07,204 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326308.tmp
05 Dec 2020 17:09:07,950 WARN  [Thread-31] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326308.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:07,968 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326308.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:07,969 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:07,969 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326308.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:07,970 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326308.tmp
05 Dec 2020 17:09:07,971 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:07,971 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326308.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326308.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:07,988 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326308.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326308
05 Dec 2020 17:09:08,056 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326309.tmp
05 Dec 2020 17:09:08,972 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,300 docs
05 Dec 2020 17:09:08,992 WARN  [Thread-32] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326309.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:09,019 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326309.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:09,020 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:09,020 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326309.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:09,021 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326309.tmp
05 Dec 2020 17:09:09,023 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:09,024 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326309.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326309.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:09,034 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326309.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326309
05 Dec 2020 17:09:09,072 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326310.tmp
05 Dec 2020 17:09:09,988 WARN  [Thread-33] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326310.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:10,002 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326310.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:10,002 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:10,004 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326310.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:10,004 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326310.tmp
05 Dec 2020 17:09:10,005 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:10,006 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326310.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326310.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:10,010 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326310.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326310
05 Dec 2020 17:09:10,046 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,400 docs
05 Dec 2020 17:09:10,078 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326311.tmp
05 Dec 2020 17:09:11,251 WARN  [Thread-34] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326311.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:11,258 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326311.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:11,258 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:11,259 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326311.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:11,260 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326311.tmp
05 Dec 2020 17:09:11,260 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:11,260 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326311.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326311.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:11,272 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326311.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326311
05 Dec 2020 17:09:11,343 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326312.tmp
05 Dec 2020 17:09:11,987 WARN  [Thread-35] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326312.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:11,988 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326312.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:11,988 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:11,989 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326312.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:11,989 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326312.tmp
05 Dec 2020 17:09:11,989 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:11,989 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326312.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326312.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:11,992 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326312.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326312
05 Dec 2020 17:09:12,001 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,500 docs
05 Dec 2020 17:09:12,134 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326313.tmp
05 Dec 2020 17:09:13,021 WARN  [Thread-36] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326313.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:13,023 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326313.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:13,023 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:13,023 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326313.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:13,024 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326313.tmp
05 Dec 2020 17:09:13,024 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:13,024 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326313.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326313.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:13,028 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326313.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326313
05 Dec 2020 17:09:13,064 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326314.tmp
05 Dec 2020 17:09:13,940 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,600 docs
05 Dec 2020 17:09:14,036 WARN  [Thread-37] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326314.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:14,044 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326314.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:14,045 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:14,046 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326314.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:14,047 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326314.tmp
05 Dec 2020 17:09:14,047 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:14,048 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326314.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326314.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:14,053 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326314.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326314
05 Dec 2020 17:09:14,165 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326315.tmp
05 Dec 2020 17:09:15,055 WARN  [Thread-38] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326315.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:15,100 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326315.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:15,100 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:15,102 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326315.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:15,114 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326315.tmp
05 Dec 2020 17:09:15,115 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:15,115 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326315.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326315.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:15,123 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326315.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326315
05 Dec 2020 17:09:15,169 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326316.tmp
05 Dec 2020 17:09:15,900 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,700 docs
05 Dec 2020 17:09:16,110 WARN  [Thread-39] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326316.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:16,112 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326316.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:16,113 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:16,113 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326316.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:16,114 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326316.tmp
05 Dec 2020 17:09:16,114 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:16,115 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326316.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326316.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:16,119 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326316.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326316
05 Dec 2020 17:09:16,154 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326317.tmp
05 Dec 2020 17:09:17,042 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,800 docs
05 Dec 2020 17:09:17,131 WARN  [Thread-40] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326317.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:17,134 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326317.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:17,134 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:17,135 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326317.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:17,135 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326317.tmp
05 Dec 2020 17:09:17,136 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:17,136 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326317.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326317.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:17,141 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326317.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326317
05 Dec 2020 17:09:17,210 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326318.tmp
05 Dec 2020 17:09:18,133 WARN  [Thread-41] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326318.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:18,144 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326318.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:18,145 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:18,145 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326318.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:18,145 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326318.tmp
05 Dec 2020 17:09:18,145 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:18,146 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326318.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326318.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:18,148 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326318.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326318
05 Dec 2020 17:09:18,184 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326319.tmp
05 Dec 2020 17:09:18,921 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 1,900 docs
05 Dec 2020 17:09:19,888 WARN  [Thread-42] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326319.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:19,896 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326319.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:19,897 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:19,897 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326319.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:19,898 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326319.tmp
05 Dec 2020 17:09:19,898 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:19,899 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326319.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326319.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:19,904 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326319.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326319
05 Dec 2020 17:09:19,980 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326320.tmp
05 Dec 2020 17:09:20,921 WARN  [Thread-43] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326320.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:20,924 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326320.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:20,925 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:20,926 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326320.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:20,926 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326320.tmp
05 Dec 2020 17:09:20,927 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:20,927 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326320.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326320.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:20,933 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326320.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326320
05 Dec 2020 17:09:21,017 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,000 docs
05 Dec 2020 17:09:21,017 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:300)  - Total docs indexed: 2,000, total skipped docs: 0
05 Dec 2020 17:09:21,018 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:302)  -     52 docs/second
05 Dec 2020 17:09:21,018 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:304)  - Run took 38 seconds and processed:
05 Dec 2020 17:09:21,018 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:306)  -     0.014 MB/sec sent to index
05 Dec 2020 17:09:21,018 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:308)  -     0.53 MB text sent to index
05 Dec 2020 17:09:21,019 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.logStats:310)  - There were 0 exceptions ignored: 
05 Dec 2020 17:09:21,042 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326321.tmp
05 Dec 2020 17:09:21,949 WARN  [Thread-44] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326321.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:21,955 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326321.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:21,956 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:21,957 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326321.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:21,957 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326321.tmp
05 Dec 2020 17:09:21,958 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:21,971 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326321.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326321.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:21,976 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326321.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326321
05 Dec 2020 17:09:22,050 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326322.tmp
05 Dec 2020 17:09:22,934 WARN  [Thread-45] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326322.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:22,951 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326322.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:22,952 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:22,953 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326322.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:22,957 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326322.tmp
05 Dec 2020 17:09:22,958 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:22,958 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326322.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326322.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:22,961 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326322.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326322
05 Dec 2020 17:09:22,995 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,100 docs
05 Dec 2020 17:09:23,072 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326323.tmp
05 Dec 2020 17:09:23,932 WARN  [Thread-46] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326323.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:23,935 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326323.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:23,935 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:23,936 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326323.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:23,936 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326323.tmp
05 Dec 2020 17:09:23,937 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:23,937 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326323.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326323.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:23,941 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326323.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326323
05 Dec 2020 17:09:24,036 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326324.tmp
05 Dec 2020 17:09:24,941 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,200 docs
05 Dec 2020 17:09:24,974 WARN  [Thread-47] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326324.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:24,976 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326324.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:24,991 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:24,992 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326324.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:24,992 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326324.tmp
05 Dec 2020 17:09:24,993 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:24,993 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326324.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326324.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:24,999 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326324.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326324
05 Dec 2020 17:09:25,039 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326325.tmp
05 Dec 2020 17:09:25,922 WARN  [Thread-48] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326325.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:25,929 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326325.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:25,930 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:25,931 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326325.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:25,932 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326325.tmp
05 Dec 2020 17:09:25,932 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:25,933 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326325.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326325.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:25,936 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326325.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326325
05 Dec 2020 17:09:26,025 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326326.tmp
05 Dec 2020 17:09:26,933 WARN  [Thread-49] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326326.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:26,936 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326326.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:26,937 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:26,937 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,300 docs
05 Dec 2020 17:09:26,937 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326326.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:26,939 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326326.tmp
05 Dec 2020 17:09:26,940 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:26,940 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326326.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326326.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:26,954 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326326.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326326
05 Dec 2020 17:09:27,011 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326327.tmp
05 Dec 2020 17:09:27,933 WARN  [Thread-50] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326327.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:27,937 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326327.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:27,938 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:27,938 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326327.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:27,938 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326327.tmp
05 Dec 2020 17:09:27,939 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:27,939 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326327.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326327.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:27,944 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326327.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326327
05 Dec 2020 17:09:27,994 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326328.tmp
05 Dec 2020 17:09:28,910 INFO  [Twitter4J Async Dispatcher[0]] (org.apache.flume.source.twitter.TwitterSource.onStatus:178)  - Processed 2,400 docs
05 Dec 2020 17:09:28,966 WARN  [Thread-51] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326328.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:28,980 WARN  [hdfs-HDFS-call-runner-6] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326328.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:28,982 ERROR [hdfs-HDFS-call-runner-6] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:28,984 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326328.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:28,984 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326328.tmp
05 Dec 2020 17:09:28,984 ERROR [hdfs-HDFS-call-runner-9] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:28,984 WARN  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326328.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326328.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:28,988 INFO  [hdfs-HDFS-call-runner-0] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326328.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326328
05 Dec 2020 17:09:29,083 INFO  [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.BucketWriter.open:234)  - Creating hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326329.tmp
05 Dec 2020 17:09:29,791 INFO  [agent-shutdown-hook] (org.apache.flume.lifecycle.LifecycleSupervisor.stop:79)  - Stopping lifecycle supervisor 11
05 Dec 2020 17:09:29,817 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.sink.hdfs.HDFSEventSink.process:459)  - process failed
java.lang.InterruptedException: Timed out before HDFS call was made. Your hdfs.callTimeout might be set too low or HDFS calls are taking too long.
	at org.apache.flume.sink.hdfs.BucketWriter.checkAndThrowInterruptedException(BucketWriter.java:660)
	at org.apache.flume.sink.hdfs.BucketWriter.flush(BucketWriter.java:419)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:442)
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:748)
05 Dec 2020 17:09:29,818 ERROR [SinkRunner-PollingRunner-DefaultSinkProcessor] (org.apache.flume.SinkRunner$PollingRunner.run:160)  - Unable to deliver event. Exception follows.
org.apache.flume.EventDeliveryException: java.lang.InterruptedException: Timed out before HDFS call was made. Your hdfs.callTimeout might be set too low or HDFS calls are taking too long.
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:463)
	at org.apache.flume.sink.DefaultSinkProcessor.process(DefaultSinkProcessor.java:68)
	at org.apache.flume.SinkRunner$PollingRunner.run(SinkRunner.java:147)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.lang.InterruptedException: Timed out before HDFS call was made. Your hdfs.callTimeout might be set too low or HDFS calls are taking too long.
	at org.apache.flume.sink.hdfs.BucketWriter.checkAndThrowInterruptedException(BucketWriter.java:660)
	at org.apache.flume.sink.hdfs.BucketWriter.flush(BucketWriter.java:419)
	at org.apache.flume.sink.hdfs.HDFSEventSink.process(HDFSEventSink.java:442)
	... 3 more
05 Dec 2020 17:09:34,819 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.HDFSEventSink.stop:492)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData
05 Dec 2020 17:09:34,825 WARN  [Thread-52] (org.apache.hadoop.hdfs.DataStreamer.run:825)  - DataStreamer Exception
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326329.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:34,825 WARN  [hdfs-HDFS-call-runner-3] (org.apache.hadoop.hdfs.DFSOutputStream.flushOrSync:739)  - Error while syncing
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326329.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:34,826 ERROR [hdfs-HDFS-call-runner-3] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:34,827 WARN  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.BucketWriter.close:360)  - pre-close flush failed
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326329.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:34,827 INFO  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.BucketWriter.close:363)  - Closing hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326329.tmp
05 Dec 2020 17:09:34,827 ERROR [hdfs-HDFS-call-runner-4] (org.apache.flume.sink.hdfs.AbstractHDFSWriter.hflushOrSync:267)  - Error while trying to hflushOrSync!
05 Dec 2020 17:09:34,828 WARN  [agent-shutdown-hook] (org.apache.flume.sink.hdfs.BucketWriter.close:370)  - failed to close() HDFSWriter for file (hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326329.tmp). Exception follows.
org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /user/Hadoop/twitter_data/FlumeData.1607168326329.tmp could only be written to 0 of the 1 minReplication nodes. There are 0 datanode(s) running and 0 node(s) are excluded in this operation.
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:2312)
	at org.apache.hadoop.hdfs.server.namenode.FSDirWriteFileOp.chooseTargetForNewBlock(FSDirWriteFileOp.java:294)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:2939)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:908)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:593)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine2.java:532)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1070)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:1020)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:948)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1845)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2952)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1562)
	at org.apache.hadoop.ipc.Client.call(Client.java:1508)
	at org.apache.hadoop.ipc.Client.call(Client.java:1405)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:234)
	at org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:119)
	at com.sun.proxy.$Proxy13.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:530)
	at sun.reflect.GeneratedMethodAccessor10.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy14.addBlock(Unknown Source)
	at org.apache.hadoop.hdfs.DFSOutputStream.addBlock(DFSOutputStream.java:1090)
	at org.apache.hadoop.hdfs.DataStreamer.locateFollowingBlock(DataStreamer.java:1867)
	at org.apache.hadoop.hdfs.DataStreamer.nextBlockOutputStream(DataStreamer.java:1669)
	at org.apache.hadoop.hdfs.DataStreamer.run(DataStreamer.java:715)
05 Dec 2020 17:09:34,856 INFO  [hdfs-HDFS-call-runner-5] (org.apache.flume.sink.hdfs.BucketWriter$8.call:629)  - Renaming hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326329.tmp to hdfs://localhost:8020/user/Hadoop/twitter_data/FlumeData.1607168326329
05 Dec 2020 17:09:34,883 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: SINK, name: HDFS stopped
05 Dec 2020 17:09:34,885 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: SINK, name: HDFS. sink.start.time == 1607168322195
05 Dec 2020 17:09:34,886 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: SINK, name: HDFS. sink.stop.time == 1607168374883
05 Dec 2020 17:09:34,886 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.complete == 0
05 Dec 2020 17:09:34,886 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.empty == 1
05 Dec 2020 17:09:34,886 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.batch.underflow == 1
05 Dec 2020 17:09:34,886 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.closed.count == 0
05 Dec 2020 17:09:34,887 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.creation.count == 41
05 Dec 2020 17:09:34,887 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.connection.failed.count == 125
05 Dec 2020 17:09:34,887 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.attempt == 41
05 Dec 2020 17:09:34,887 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: SINK, name: HDFS. sink.event.drain.sucess == 0
05 Dec 2020 17:09:34,887 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:150)  - Component type: CHANNEL, name: FileChannel stopped
05 Dec 2020 17:09:34,888 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:156)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.start.time == 1607168322190
05 Dec 2020 17:09:34,888 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:162)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.stop.time == 1607168374887
05 Dec 2020 17:09:34,888 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.capacity == 10000
05 Dec 2020 17:09:34,888 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.current.size == 41
05 Dec 2020 17:09:34,888 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.put.attempt == 41
05 Dec 2020 17:09:34,888 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.put.success == 41
05 Dec 2020 17:09:34,888 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.take.attempt == 44
05 Dec 2020 17:09:34,888 INFO  [agent-shutdown-hook] (org.apache.flume.instrumentation.MonitoredCounterGroup.stop:178)  - Shutdown Metric for type: CHANNEL, name: FileChannel. channel.event.take.success == 0
05 Dec 2020 17:09:34,888 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:150)  - Twitter source Twitter stopping...
05 Dec 2020 17:09:34,904 INFO  [Twitter Stream consumer-1[Disposing thread]] (twitter4j.internal.logging.SLF4JLogger.info:83)  - Inflater has been closed
05 Dec 2020 17:09:34,905 ERROR [Twitter Stream consumer-1[Disposing thread]] (org.apache.flume.source.twitter.TwitterSource.onException:331)  - Exception while streaming tweets
java.lang.NullPointerException: Inflater has been closed
	at java.util.zip.Inflater.ensureOpen(Inflater.java:389)
	at java.util.zip.Inflater.inflate(Inflater.java:257)
	at java.util.zip.InflaterInputStream.read(InflaterInputStream.java:152)
	at java.util.zip.GZIPInputStream.read(GZIPInputStream.java:117)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:284)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:326)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:178)
	at java.io.InputStreamReader.read(InputStreamReader.java:184)
	at java.io.BufferedReader.fill(BufferedReader.java:161)
	at java.io.BufferedReader.readLine(BufferedReader.java:324)
	at java.io.BufferedReader.readLine(BufferedReader.java:389)
	at twitter4j.StatusStreamBase.handleNextElement(StatusStreamBase.java:85)
	at twitter4j.StatusStreamImpl.next(StatusStreamImpl.java:57)
	at twitter4j.TwitterStreamImpl$TwitterStreamConsumer.run(TwitterStreamImpl.java:478)
05 Dec 2020 17:09:34,911 INFO  [agent-shutdown-hook] (org.apache.flume.source.twitter.TwitterSource.stop:153)  - Twitter source Twitter stopped.
05 Dec 2020 17:09:34,912 INFO  [agent-shutdown-hook] (org.apache.flume.node.PollingPropertiesFileConfigurationProvider.stop:83)  - Configuration provider stopping
